{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dafc480",
   "metadata": {},
   "source": [
    "# Distillation. Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bba164c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: dmykhailov (dmykhailov-kyiv-school-of-economics) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "machine = \"local\"\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bdd7d3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ff175635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1+cu128\n",
      "Device: NVIDIA GeForce RTX 5050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from typing import cast\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import warnings\n",
    "from notebooks_config import setup_logging, CustomLogger\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ba1c03c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;105;254;105m\n",
      "[2025-12-11 00:41:42]\n",
      "SUCCESS: Logging configured successfully ✅\u001b[0m\n",
      "\u001b[38;2;105;254;105m\n",
      "[2025-12-11 00:41:42]\n",
      "SUCCESS: Logging configuration test completed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger = setup_logging(level=logging.DEBUG, full_color=True, include_function=False)\n",
    "logger = cast(CustomLogger, logger)  # Type hinting\n",
    "logger.success(\"Logging configuration test completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e452128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESCRIPTION_FULL: swinv2_tiny_window8_256-local_train[5]Folds_epochs1_bs64_gradacc1_lr2e-05_wd0.01_dr0.2_hr0.5\n",
      "Effective batch size: 64\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = 0\n",
    "\n",
    "LR = 2e-5\n",
    "EPOCHS = 1\n",
    "N_FOLDS = 5\n",
    "GRAD_ACCUM = 1\n",
    "BATCH_SIZE = 16\n",
    "DROPOUT_RATE = 0.2\n",
    "WEIGHT_DECAY = 0.01\n",
    "HIDDEN_RATIO = 0.5\n",
    "TRAIN_SPLIT_RATIO = 0.02 # Used if N_FOLDS = 0\n",
    "\n",
    "MODEL = \"swinv2_tiny_window8_256\"\n",
    "PROJECT_NAME = \"csiro-image2biomass-prediction\"\n",
    "CHECKPOINTS_DIR = \"./kaggle/checkpoints/teacher/\"\n",
    "\n",
    "# Each patch is 1000x1000, resize to 768x768 for vision transformers\n",
    "SIZE = 768\n",
    "\n",
    "DESCRIPTION = machine + \\\n",
    "    (f\"_train{TRAIN_SPLIT_RATIO}\" if N_FOLDS == 0 else f\"_train[{N_FOLDS}]Folds\")\n",
    "DESCRIPTION_FULL = MODEL + \"-\" + DESCRIPTION + \\\n",
    "    f\"_epochs{EPOCHS}_bs{BATCH_SIZE}_gradacc{GRAD_ACCUM}_lr{LR}_wd{WEIGHT_DECAY}_dr{DROPOUT_RATE}_hr{HIDDEN_RATIO}\"\n",
    "SUBMISSION_NAME = f\"{DESCRIPTION_FULL}_submission.csv\"\n",
    "SUBMISSION_ENSEMBLE_NAME = f\"{DESCRIPTION_FULL}_ensemble_submission.csv\"\n",
    "SUBMISSION_MSG = DESCRIPTION_FULL.replace(\"_\", \" \")\n",
    "\n",
    "SEED = 1488\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "pl.seed_everything(SEED)\n",
    "\n",
    "print(\"DESCRIPTION_FULL:\", DESCRIPTION_FULL)\n",
    "print(f\"Effective batch size: {BATCH_SIZE * GRAD_ACCUM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1804fc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 5050 Laptop GPU\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)\n",
    "print()\n",
    "\n",
    "# Additional Info when using cuda\n",
    "if DEVICE.type == 'cuda':\n",
    "    # clean GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    torch.set_float32_matmul_precision('high') if machine == \"local\" else None\n",
    "\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3, 1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b9504",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e402a80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (1071, 9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sample_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sampling_Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "State",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Species",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Pre_GSHH_NDVI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Height_Ave_cm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1e1c55f2-17ea-4698-887c-8a65724fd855",
       "rows": [
        [
         "0",
         "ID1011485656__Dry_Clover_g",
         "train/ID1011485656.jpg",
         "2015/9/4",
         "Tas",
         "Ryegrass_Clover",
         "0.62",
         "4.6667",
         "Dry_Clover_g",
         "0.0"
        ],
        [
         "1",
         "ID1011485656__Dry_Dead_g",
         "train/ID1011485656.jpg",
         "2015/9/4",
         "Tas",
         "Ryegrass_Clover",
         "0.62",
         "4.6667",
         "Dry_Dead_g",
         "31.9984"
        ],
        [
         "2",
         "ID1011485656__Dry_Green_g",
         "train/ID1011485656.jpg",
         "2015/9/4",
         "Tas",
         "Ryegrass_Clover",
         "0.62",
         "4.6667",
         "Dry_Green_g",
         "16.275"
        ],
        [
         "5",
         "ID1012260530__Dry_Clover_g",
         "train/ID1012260530.jpg",
         "2015/4/1",
         "NSW",
         "Lucerne",
         "0.55",
         "16.0",
         "Dry_Clover_g",
         "0.0"
        ],
        [
         "6",
         "ID1012260530__Dry_Dead_g",
         "train/ID1012260530.jpg",
         "2015/4/1",
         "NSW",
         "Lucerne",
         "0.55",
         "16.0",
         "Dry_Dead_g",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Sampling_Date</th>\n",
       "      <th>State</th>\n",
       "      <th>Species</th>\n",
       "      <th>Pre_GSHH_NDVI</th>\n",
       "      <th>Height_Ave_cm</th>\n",
       "      <th>target_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1011485656__Dry_Clover_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Clover_g</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1011485656__Dry_Dead_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Dead_g</td>\n",
       "      <td>31.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1011485656__Dry_Green_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Green_g</td>\n",
       "      <td>16.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID1012260530__Dry_Clover_g</td>\n",
       "      <td>train/ID1012260530.jpg</td>\n",
       "      <td>2015/4/1</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Lucerne</td>\n",
       "      <td>0.55</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>Dry_Clover_g</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID1012260530__Dry_Dead_g</td>\n",
       "      <td>train/ID1012260530.jpg</td>\n",
       "      <td>2015/4/1</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Lucerne</td>\n",
       "      <td>0.55</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>Dry_Dead_g</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id              image_path Sampling_Date State  \\\n",
       "0  ID1011485656__Dry_Clover_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "1    ID1011485656__Dry_Dead_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "2   ID1011485656__Dry_Green_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "5  ID1012260530__Dry_Clover_g  train/ID1012260530.jpg      2015/4/1   NSW   \n",
       "6    ID1012260530__Dry_Dead_g  train/ID1012260530.jpg      2015/4/1   NSW   \n",
       "\n",
       "           Species  Pre_GSHH_NDVI  Height_Ave_cm   target_name   target  \n",
       "0  Ryegrass_Clover           0.62         4.6667  Dry_Clover_g   0.0000  \n",
       "1  Ryegrass_Clover           0.62         4.6667    Dry_Dead_g  31.9984  \n",
       "2  Ryegrass_Clover           0.62         4.6667   Dry_Green_g  16.2750  \n",
       "5          Lucerne           0.55        16.0000  Dry_Clover_g   0.0000  \n",
       "6          Lucerne           0.55        16.0000    Dry_Dead_g   0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH_DATA = './kaggle/input/csiro-biomass'\n",
    "PATH_TRAIN_CSV = os.path.join(PATH_DATA, 'train.csv')\n",
    "PATH_TEST_CSV = os.path.join(PATH_DATA, 'test.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(PATH_DATA, 'train')\n",
    "PATH_TEST_IMG = os.path.join(PATH_DATA, 'test')\n",
    "\n",
    "df = pd.read_csv(PATH_TRAIN_CSV)\n",
    "df = df[~df['target_name'].isin(['Dry_Total_g', 'GDM_g'])]  # Remove unneeded targets\n",
    "print(f\"Dataset size: {df.shape}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1285873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(357, 9)\n",
      "               image_path Sampling_Date State            Species  \\\n",
      "0  train/ID1011485656.jpg      2015/9/4   Tas    Ryegrass_Clover   \n",
      "1  train/ID1012260530.jpg      2015/4/1   NSW            Lucerne   \n",
      "2  train/ID1025234388.jpg      2015/9/1    WA  SubcloverDalkeith   \n",
      "3  train/ID1028611175.jpg     2015/5/18   Tas           Ryegrass   \n",
      "4  train/ID1035947949.jpg     2015/9/11   Tas           Ryegrass   \n",
      "\n",
      "   Height_Ave_cm  Pre_GSHH_NDVI  Dry_Clover_g  Dry_Dead_g  Dry_Green_g  \n",
      "0         4.6667           0.62        0.0000     31.9984      16.2750  \n",
      "1        16.0000           0.55        0.0000      0.0000       7.6000  \n",
      "2         1.0000           0.38        6.0500      0.0000       0.0000  \n",
      "3         5.0000           0.66        0.0000     30.9703      24.2376  \n",
      "4         3.5000           0.54        0.4343     23.2239      10.5261  \n"
     ]
    }
   ],
   "source": [
    "# pivot the dataframe to have one row per image with multiple target columns\n",
    "tabular_df = df.pivot_table(index=['image_path', 'Sampling_Date', 'State', 'Species', 'Height_Ave_cm', 'Pre_GSHH_NDVI'],\n",
    "                              columns='target_name', values='target', aggfunc='first').reset_index()\n",
    "tabular_df.columns.name = None  # remove the aggregation name\n",
    "print(tabular_df.shape)\n",
    "print(tabular_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c96a1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_path', 'Sampling_Date', 'State', 'Species', 'Height_Ave_cm', 'Pre_GSHH_NDVI', 'Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g']\n"
     ]
    }
   ],
   "source": [
    "print(tabular_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0220a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols  = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g']\n",
    "num_features = ['Height_Ave_cm', 'Pre_GSHH_NDVI']\n",
    "cat_features = ['Species', 'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b44b2e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features), # normalizing numeric features\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), cat_features) # OHE for categorical features\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdb7c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_data = preprocessor.fit_transform(tabular_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bd47682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(357, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.28520388, -0.24631873,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.81823967, -0.70706013,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.64220462, -1.82600352,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [-0.25275281,  0.01696207,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.39879723, -0.77288032,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tabular_data.shape)\n",
    "display(tabular_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbb541",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "413e7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"Dataset for biomass prediction with image + tabular features\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        df: pd.DataFrame,\n",
    "        tabular_features: np.ndarray,\n",
    "        target_cols: list[str],\n",
    "        img_dir: str,\n",
    "        transform: transforms.Compose | None = None,\n",
    "        is_test: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: DataFrame with image_id, image_path, and target columns\n",
    "            tabular_features: Preprocessed tabular features (shape: [n_samples, n_features])\n",
    "            target_cols: List of target column names\n",
    "            img_dir: Root directory for images\n",
    "            transform: torchvision transform pipeline\n",
    "            is_test: If True, targets are not expected in df\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tabular_features = tabular_features\n",
    "        self.target_cols = target_cols\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        assert len(self.df) == len(self.tabular_features), \\\n",
    "            f\"DataFrame length {len(self.df)} != tabular features length {len(self.tabular_features)}\"\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            dict with keys:\n",
    "                - 'left_image': tensor [C, H, W]\n",
    "                - 'right_image': tensor [C, H, W]\n",
    "                - 'tabular': tensor [n_features]\n",
    "                - 'targets': tensor [n_targets] (if not test)\n",
    "                - 'image_id': str\n",
    "        \"\"\"\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, row['image_path'].replace('train/', '').replace('test/', ''))\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Cannot load image: {img_path}\")\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Split into left and right patches\n",
    "        # Original image shape: [H, W, C] = [1000, 2000, 3]\n",
    "        h, w, c = image.shape\n",
    "        mid_w = w // 2\n",
    "        \n",
    "        left_patch = image[:, :mid_w, :]   # [1000, 1000, 3]\n",
    "        right_patch = image[:, mid_w:, :]  # [1000, 1000, 3]\n",
    "        \n",
    "        # Convert to PIL Image for torchvision transforms\n",
    "        left_pil = Image.fromarray(left_patch)\n",
    "        right_pil = Image.fromarray(right_patch)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            left_tensor = self.transform(left_pil)\n",
    "            right_tensor = self.transform(right_pil)\n",
    "        else:\n",
    "            left_tensor = transforms.ToTensor()(left_pil)\n",
    "            right_tensor = transforms.ToTensor()(right_pil)\n",
    "        \n",
    "        # Get tabular features\n",
    "        tabular = torch.tensor(self.tabular_features[idx], dtype=torch.float32)\n",
    "        \n",
    "        # Prepare output\n",
    "        output = {\n",
    "            'left_image': left_tensor,\n",
    "            'right_image': right_tensor,\n",
    "            'tabular': tabular,\n",
    "            'image_id': row['image_path'].split('/')[-1].replace('.jpg', '')\n",
    "        }\n",
    "        \n",
    "        # Add targets if not test\n",
    "        if not self.is_test:\n",
    "            targets = torch.tensor(\n",
    "                row[self.target_cols].values.astype(np.float32),\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            output['targets'] = targets\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "14e0673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_img_data_stat(df: pd.DataFrame):\n",
    "    \"\"\"Calculate mean and std of image data for normalization.\"\"\"\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    loader = tqdm(df['image_path'], desc=\"Calculating image stats\")\n",
    "    \n",
    "    for img_path in loader:\n",
    "        full_path = os.path.join(PATH_TRAIN_IMG, img_path.replace('train/', '').replace('test/', ''))\n",
    "        image = cv2.imread(full_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image / 255.0  # Normalize to [0, 1]\n",
    "        \n",
    "        means.append(np.mean(image, axis=(0, 1)))\n",
    "        stds.append(np.std(image, axis=(0, 1)))\n",
    "    \n",
    "    mean = np.mean(means, axis=0)\n",
    "    std = np.mean(stds, axis=0)\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7b4abf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating image stats: 100%|██████████| 357/357 [00:48<00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image Mean: [0.44173591 0.50362967 0.30579783], Std: [0.2364247  0.23557117 0.22199257]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_mean, train_std = calculate_img_data_stat(tabular_df)\n",
    "print(f\"Train Image Mean: {train_mean}, Std: {train_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f7f4ee23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_tiny_patch4_window8_256.pth',\n",
       " 'hf_hub_id': 'timm/swinv2_tiny_window8_256.ms_in1k',\n",
       " 'architecture': 'swinv2_tiny_window8_256',\n",
       " 'tag': 'ms_in1k',\n",
       " 'custom_load': False,\n",
       " 'input_size': (3, 256, 256),\n",
       " 'fixed_input_size': True,\n",
       " 'interpolation': 'bicubic',\n",
       " 'crop_pct': 0.9,\n",
       " 'crop_mode': 'center',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'num_classes': 1000,\n",
       " 'pool_size': (8, 8),\n",
       " 'first_conv': 'patch_embed.proj',\n",
       " 'classifier': 'head.fc',\n",
       " 'license': 'mit'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image backbone (processes each patch independently)\n",
    "temp_backbone = timm.create_model(\n",
    "    MODEL,\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classification head\n",
    "    global_pool='avg'\n",
    ")\n",
    "\n",
    "temp_backbone.default_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d60de83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_size = temp_backbone.default_cfg['input_size']\n",
    "mean = temp_backbone.default_cfg['mean']\n",
    "std = temp_backbone.default_cfg['std']\n",
    "\n",
    "SIZE = int(inputs_size[1]) if inputs_size is not None and inputs_size[1] == inputs_size[2] else 256\n",
    "\n",
    "# Get backbone output dimension\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        dummy = torch.randn(1, 3, SIZE, SIZE)\n",
    "        feat_dim = temp_backbone(dummy).shape[1]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting backbone feature dimension: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "06c353b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cc5ef120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left image shape: torch.Size([3, 256, 256])\n",
      "Right image shape: torch.Size([3, 256, 256])\n",
      "Tabular shape: torch.Size([21])\n",
      "Targets shape: torch.Size([3])\n",
      "Image ID: ID1011485656\n",
      "Target values: tensor([ 0.0000, 31.9984, 16.2750])\n"
     ]
    }
   ],
   "source": [
    "# Create dataset instance\n",
    "train_dataset = BiomassDataset(\n",
    "    df=tabular_df,\n",
    "    tabular_features=tabular_data,\n",
    "    target_cols=target_cols,\n",
    "    img_dir=PATH_TRAIN_IMG,\n",
    "    transform=train_transform,\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "# Test it\n",
    "sample = train_dataset[0]\n",
    "print(f\"Left image shape: {sample['left_image'].shape}\")\n",
    "print(f\"Right image shape: {sample['right_image'].shape}\")\n",
    "print(f\"Tabular shape: {sample['tabular'].shape}\")\n",
    "print(f\"Targets shape: {sample['targets'].shape}\")\n",
    "print(f\"Image ID: {sample['image_id']}\")\n",
    "print(f\"Target values: {sample['targets']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f322e7",
   "metadata": {},
   "source": [
    "## Spliting Data (StratifiedKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "29b90a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(date_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert date string to season.\n",
    "    \n",
    "    Args:\n",
    "        date_str: Date in format 'YYYY/M/D' or 'YYYY/MM/DD'\n",
    "    \n",
    "    Returns:\n",
    "        Season name: 'Summer', 'Autumn', 'Winter', 'Spring'\n",
    "    \"\"\"\n",
    "    # Parse month from date string\n",
    "    month = int(date_str.split('/')[1])\n",
    "    \n",
    "    # Australian seasons (Southern Hemisphere)\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Summer'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Autumn'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Winter'\n",
    "    else:  # 9, 10, 11\n",
    "        return 'Spring'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d5e023e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique stratification groups:\n",
      "strat_group\n",
      "Spring_Tas_Ryegrass_Clover                                                41\n",
      "Winter_Vic_Phalaris_Clover                                                32\n",
      "Autumn_Tas_Ryegrass                                                       22\n",
      "Winter_Vic_Ryegrass_Clover                                                21\n",
      "Spring_Tas_Clover                                                         21\n",
      "Winter_WA_Clover                                                          20\n",
      "Winter_Tas_Ryegrass_Clover                                                18\n",
      "Autumn_NSW_Lucerne                                                        15\n",
      "Spring_Vic_Ryegrass_Clover                                                11\n",
      "Spring_Vic_Phalaris_BarleyGrass_SilverGrass_SpearGrass_Clover_Capeweed    11\n",
      "Spring_NSW_Fescue                                                         11\n",
      "Summer_NSW_Fescue_CrumbWeed                                               10\n",
      "Spring_Vic_Phalaris_Clover                                                10\n",
      "Winter_Tas_WhiteClover                                                    10\n",
      "Winter_Vic_Ryegrass                                                       10\n",
      "Winter_Tas_Ryegrass                                                       10\n",
      "Spring_Tas_Ryegrass                                                        9\n",
      "Summer_NSW_Fescue                                                          9\n",
      "Summer_NSW_Phalaris                                                        8\n",
      "Autumn_NSW_Fescue                                                          8\n",
      "Winter_Vic_Phalaris_Ryegrass_Clover                                        8\n",
      "Summer_NSW_Lucerne                                                         7\n",
      "Spring_Vic_Phalaris_Clover_Ryegrass_Barleygrass_Bromegrass                 7\n",
      "Autumn_Tas_Ryegrass_Clover                                                 7\n",
      "Summer_NSW_Ryegrass                                                        7\n",
      "Spring_WA_SubcloverLosa                                                    5\n",
      "Spring_WA_Ryegrass                                                         4\n",
      "Spring_WA_SubcloverDalkeith                                                3\n",
      "Winter_Vic_Mixed                                                           2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total groups: 29\n"
     ]
    }
   ],
   "source": [
    "# Add season column\n",
    "tabular_df['Season'] = tabular_df['Sampling_Date'].apply(get_season)\n",
    "\n",
    "# Create stratification column combining Season, State, and Species\n",
    "tabular_df['strat_group'] = (\n",
    "    tabular_df['Season'].astype(str) + '_' +\n",
    "    tabular_df['State'].astype(str) + '_' +\n",
    "    tabular_df['Species'].astype(str)\n",
    ")\n",
    "\n",
    "print(\"Unique stratification groups:\")\n",
    "print(tabular_df['strat_group'].value_counts())\n",
    "print(f\"\\nTotal groups: {tabular_df['strat_group'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7d5f0fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "  Train samples: 285\n",
      "  Val samples: 72\n",
      "\n",
      "Fold 2:\n",
      "  Train samples: 285\n",
      "  Val samples: 72\n",
      "\n",
      "Fold 3:\n",
      "  Train samples: 286\n",
      "  Val samples: 71\n",
      "\n",
      "Fold 4:\n",
      "  Train samples: 286\n",
      "  Val samples: 71\n",
      "\n",
      "Fold 5:\n",
      "  Train samples: 286\n",
      "  Val samples: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:813: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize StratifiedKFold\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Get stratification labels\n",
    "strat_labels = tabular_df['strat_group'].values\n",
    "\n",
    "# Create fold assignments\n",
    "tabular_df['fold'] = -1\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(tabular_df, strat_labels)):\n",
    "    tabular_df.loc[val_idx, 'fold'] = fold_idx\n",
    "    \n",
    "    print(f\"\\nFold {fold_idx + 1}:\")\n",
    "    print(f\"  Train samples: {len(train_idx)}\")\n",
    "    print(f\"  Val samples: {len(val_idx)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "20130d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratification verification:\n",
      "\n",
      "Fold 1:\n",
      "  Season distribution:\n",
      "Season\n",
      "Winter    0.361\n",
      "Spring    0.347\n",
      "Autumn    0.167\n",
      "Summer    0.125\n",
      "Name: proportion, dtype: float64\n",
      "  State distribution:\n",
      "State\n",
      "Tas    0.389\n",
      "Vic    0.319\n",
      "NSW    0.222\n",
      "WA     0.069\n",
      "Name: proportion, dtype: float64\n",
      "  Species distribution:\n",
      "Species\n",
      "Ryegrass_Clover                                                0.292\n",
      "Ryegrass                                                       0.167\n",
      "Phalaris_Clover                                                0.111\n",
      "Clover                                                         0.111\n",
      "Fescue                                                         0.083\n",
      "Lucerne                                                        0.056\n",
      "Fescue_CrumbWeed                                               0.028\n",
      "Phalaris                                                       0.028\n",
      "WhiteClover                                                    0.028\n",
      "Phalaris_Clover_Ryegrass_Barleygrass_Bromegrass                0.028\n",
      "Phalaris_BarleyGrass_SilverGrass_SpearGrass_Clover_Capeweed    0.028\n",
      "SubcloverLosa                                                  0.014\n",
      "Phalaris_Ryegrass_Clover                                       0.014\n",
      "Mixed                                                          0.014\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Fold 2:\n",
      "  Season distribution:\n",
      "Season\n",
      "Spring    0.389\n",
      "Winter    0.375\n",
      "Autumn    0.125\n",
      "Summer    0.111\n",
      "Name: proportion, dtype: float64\n",
      "  State distribution:\n",
      "State\n",
      "Tas    0.375\n",
      "Vic    0.333\n",
      "NSW    0.194\n",
      "WA     0.097\n",
      "Name: proportion, dtype: float64\n",
      "  Species distribution:\n",
      "Species\n",
      "Ryegrass_Clover                                                0.278\n",
      "Ryegrass                                                       0.167\n",
      "Phalaris_Clover                                                0.125\n",
      "Clover                                                         0.111\n",
      "Fescue                                                         0.069\n",
      "Lucerne                                                        0.056\n",
      "Phalaris_BarleyGrass_SilverGrass_SpearGrass_Clover_Capeweed    0.042\n",
      "Fescue_CrumbWeed                                               0.028\n",
      "Phalaris                                                       0.028\n",
      "WhiteClover                                                    0.028\n",
      "SubcloverDalkeith                                              0.014\n",
      "Phalaris_Clover_Ryegrass_Barleygrass_Bromegrass                0.014\n",
      "Phalaris_Ryegrass_Clover                                       0.014\n",
      "Mixed                                                          0.014\n",
      "SubcloverLosa                                                  0.014\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Fold 3:\n",
      "  Season distribution:\n",
      "Season\n",
      "Spring    0.380\n",
      "Winter    0.380\n",
      "Autumn    0.127\n",
      "Summer    0.113\n",
      "Name: proportion, dtype: float64\n",
      "  State distribution:\n",
      "State\n",
      "Tas    0.380\n",
      "Vic    0.310\n",
      "NSW    0.211\n",
      "WA     0.099\n",
      "Name: proportion, dtype: float64\n",
      "  Species distribution:\n",
      "Species\n",
      "Ryegrass_Clover                                                0.268\n",
      "Ryegrass                                                       0.169\n",
      "Phalaris_Clover                                                0.127\n",
      "Clover                                                         0.113\n",
      "Fescue                                                         0.085\n",
      "Lucerne                                                        0.056\n",
      "WhiteClover                                                    0.028\n",
      "Phalaris_BarleyGrass_SilverGrass_SpearGrass_Clover_Capeweed    0.028\n",
      "Phalaris                                                       0.028\n",
      "Fescue_CrumbWeed                                               0.028\n",
      "Phalaris_Ryegrass_Clover                                       0.028\n",
      "Phalaris_Clover_Ryegrass_Barleygrass_Bromegrass                0.014\n",
      "SubcloverDalkeith                                              0.014\n",
      "SubcloverLosa                                                  0.014\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Fold 4:\n",
      "  Season distribution:\n",
      "Season\n",
      "Spring    0.380\n",
      "Winter    0.366\n",
      "Autumn    0.141\n",
      "Summer    0.113\n",
      "Name: proportion, dtype: float64\n",
      "  State distribution:\n",
      "State\n",
      "Tas    0.394\n",
      "Vic    0.296\n",
      "NSW    0.211\n",
      "WA     0.099\n",
      "Name: proportion, dtype: float64\n",
      "  Species distribution:\n",
      "Species\n",
      "Ryegrass_Clover                                                0.268\n",
      "Ryegrass                                                       0.169\n",
      "Clover                                                         0.127\n",
      "Phalaris_Clover                                                0.113\n",
      "Fescue                                                         0.085\n",
      "Lucerne                                                        0.070\n",
      "Phalaris_Ryegrass_Clover                                       0.028\n",
      "WhiteClover                                                    0.028\n",
      "Fescue_CrumbWeed                                               0.028\n",
      "Phalaris_BarleyGrass_SilverGrass_SpearGrass_Clover_Capeweed    0.028\n",
      "Phalaris                                                       0.014\n",
      "Phalaris_Clover_Ryegrass_Barleygrass_Bromegrass                0.014\n",
      "SubcloverLosa                                                  0.014\n",
      "SubcloverDalkeith                                              0.014\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Fold 5:\n",
      "  Season distribution:\n",
      "Season\n",
      "Spring    0.366\n",
      "Winter    0.352\n",
      "Autumn    0.169\n",
      "Summer    0.113\n",
      "Name: proportion, dtype: float64\n",
      "  State distribution:\n",
      "State\n",
      "Tas    0.394\n",
      "Vic    0.310\n",
      "NSW    0.211\n",
      "WA     0.085\n",
      "Name: proportion, dtype: float64\n",
      "  Species distribution:\n",
      "Species\n",
      "Ryegrass_Clover                                                0.268\n",
      "Ryegrass                                                       0.197\n",
      "Clover                                                         0.113\n",
      "Phalaris_Clover                                                0.113\n",
      "Fescue                                                         0.070\n",
      "Lucerne                                                        0.070\n",
      "WhiteClover                                                    0.028\n",
      "Phalaris_Ryegrass_Clover                                       0.028\n",
      "Fescue_CrumbWeed                                               0.028\n",
      "Phalaris_Clover_Ryegrass_Barleygrass_Bromegrass                0.028\n",
      "Phalaris_BarleyGrass_SilverGrass_SpearGrass_Clover_Capeweed    0.028\n",
      "Phalaris                                                       0.014\n",
      "SubcloverLosa                                                  0.014\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verify stratification worked\n",
    "print(\"Stratification verification:\")\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    fold_df = tabular_df[tabular_df['fold'] == fold]\n",
    "    print(f\"\\nFold {fold + 1}:\")\n",
    "    print(f\"  Season distribution:\")\n",
    "    print(fold_df['Season'].value_counts(normalize=True).round(3))\n",
    "    print(f\"  State distribution:\")\n",
    "    print(fold_df['State'].value_counts(normalize=True).round(3))\n",
    "    print(f\"  Species distribution:\")\n",
    "    print(fold_df['Species'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7cea12fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_data(df: pd.DataFrame, fold: int):\n",
    "    \"\"\"\n",
    "    Get train/val split for specific fold.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'fold' column\n",
    "        fold: Fold index to use as validation\n",
    "    \n",
    "    Returns:\n",
    "        train_df, val_df\n",
    "    \"\"\"\n",
    "    train_df = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    val_df = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "25e99df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(fold: int, bs: int) -> tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"Train on specific fold.\"\"\"\n",
    "    train_df, val_df = get_fold_data(tabular_df, fold)\n",
    "\n",
    "    print(f\"Training fold {fold}:\")\n",
    "    print(f\"  Train size: {len(train_df)}\")\n",
    "    print(f\"  Val size: {len(val_df)}\")\n",
    "\n",
    "    # Fit preprocessor only on train\n",
    "    preprocessor.fit(train_df)\n",
    "    train_tabular = preprocessor.transform(train_df)\n",
    "    val_tabular = preprocessor.transform(val_df)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = BiomassDataset(\n",
    "        df=train_df,\n",
    "        tabular_features=train_tabular,\n",
    "        target_cols=target_cols,\n",
    "        img_dir=PATH_TRAIN_IMG,\n",
    "        transform=train_transform,\n",
    "        is_test=False\n",
    "    )\n",
    "\n",
    "    val_dataset = BiomassDataset(\n",
    "        df=val_df,\n",
    "        tabular_features=val_tabular,\n",
    "        target_cols=target_cols,\n",
    "        img_dir=PATH_TRAIN_IMG,\n",
    "        transform=val_transform,\n",
    "        is_test=False\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=bs,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=bs,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    print(f\"Train batches: {len(train_loader)}\")\n",
    "    print(f\"Val batches: {len(val_loader)}\")\n",
    "    print(f\"Tabular features dimension: {train_tabular.shape[1]}\")\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd54d9",
   "metadata": {},
   "source": [
    "## Ligtning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9e8b2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassTeacherModel(pl.LightningModule):\n",
    "    \"\"\"Teacher model for biomass prediction with dual-patch image + tabular features\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_name: str = 'swinv2_tiny_window8_256',\n",
    "        tabular_dim: int = 10,\n",
    "        num_targets: int = 3,\n",
    "        lr: float = 1e-4,\n",
    "        weight_decay: float = 1e-5,\n",
    "        hidden_ratio: float = 0.5,\n",
    "        dropout: float = 0.2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            backbone_name: timm model name\n",
    "            tabular_dim: dimension of tabular features\n",
    "            num_targets: number of regression targets\n",
    "            lr: learning rate\n",
    "            weight_decay: optimizer weight decay\n",
    "            hidden_ratio: ratio of hidden layer size relative to feature dim\n",
    "            dropout: dropout probability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Image backbone (processes each patch independently)\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name,\n",
    "            pretrained=True,\n",
    "            num_classes=0,  # remove classification head\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        \n",
    "        # Get backbone output dimension\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, SIZE, SIZE)\n",
    "            feat_dim = self.backbone(dummy).shape[1]\n",
    "        \n",
    "        self.feat_dim = feat_dim\n",
    "        self.combined_dim = feat_dim * 2 + tabular_dim  # left + right + tabular\n",
    "        \n",
    "        # Regression heads\n",
    "        hidden_size = max(32, int(self.combined_dim * hidden_ratio))\n",
    "        \n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.combined_dim, hidden_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_size, 1)\n",
    "            )\n",
    "        \n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "        \n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "        \n",
    "        logger.info(f\"Model initialized: backbone={backbone_name}, feat_dim={feat_dim}, combined_dim={self.combined_dim}\")\n",
    "    \n",
    "    def forward(self, batch: dict) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch: dict with 'left_image', 'right_image', 'tabular'\n",
    "        \n",
    "        Returns:\n",
    "            (green, clover, dead) predictions as separate tensors\n",
    "        \"\"\"\n",
    "        # Extract features from each patch\n",
    "        left_feat = self.backbone(batch['left_image'])   # [B, D]\n",
    "        right_feat = self.backbone(batch['right_image'])  # [B, D]\n",
    "        \n",
    "        # Combine all features\n",
    "        combined = torch.cat([left_feat, right_feat, batch['tabular']], dim=1)  # [B, 2*D + tab_dim]\n",
    "        \n",
    "        # Predict each target (apply softplus to ensure positive values)\n",
    "        green = self.softplus(self.head_green(combined)).squeeze(1)   # [B]\n",
    "        clover = self.softplus(self.head_clover(combined)).squeeze(1)  # [B]\n",
    "        dead = self.softplus(self.head_dead(combined)).squeeze(1)     # [B]\n",
    "        \n",
    "        return green, clover, dead\n",
    "    \n",
    "    def compute_loss(self, pred: tuple, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: (green, clover, dead) predictions\n",
    "            target: [B, 3] ground truth targets [green, clover, dead]\n",
    "        \n",
    "        Returns:\n",
    "            MSE loss\n",
    "        \"\"\"\n",
    "        green_pred, clover_pred, dead_pred = pred\n",
    "        green_true = target[:, 2]  # Dry_Green_g\n",
    "        clover_true = target[:, 0]  # Dry_Clover_g\n",
    "        dead_true = target[:, 1]   # Dry_Dead_g\n",
    "        \n",
    "        loss_green = F.mse_loss(green_pred, green_true)\n",
    "        loss_clover = F.mse_loss(clover_pred, clover_true)\n",
    "        loss_dead = F.mse_loss(dead_pred, dead_true)\n",
    "        \n",
    "        total_loss = loss_green + loss_clover + loss_dead\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def training_step(self, batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        pred = self(batch)\n",
    "        loss = self.compute_loss(pred, batch['targets'])\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        pred = self(batch)\n",
    "        loss = self.compute_loss(pred, batch['targets'])\n",
    "        \n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        \n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=self.trainer.max_epochs,\n",
    "            eta_min=self.hparams.lr * 0.01\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'epoch'\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b85bdfb",
   "metadata": {},
   "source": [
    "## Folds Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59f4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 0:\n",
      "  Train size: 285\n",
      "  Val size: 72\n",
      "Train batches: 5\n",
      "Val batches: 2\n",
      "Tabular features dimension: 21\n",
      "\u001b[38;2;161;247;255m\n",
      "[2025-12-11 00:55:28]\n",
      "INFO: Model initialized: backbone=swinv2_tiny_window8_256, feat_dim=768, combined_dim=1557\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\lightning_fabric\\connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmykhailov\u001b[0m (\u001b[33mdmykhailov-kyiv-school-of-economics\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb\\run-20251211_005530-g0urxb08</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction/runs/g0urxb08' target=\"_blank\">swinv2_tiny_window8_256-local_train[5]Folds_epochs1_bs64_gradacc1_lr2e-05_wd0.01_dr0.2_hr0.5-fold0</a></strong> to <a href='https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction' target=\"_blank\">https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction/runs/g0urxb08' target=\"_blank\">https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction/runs/g0urxb08</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\model_summary\\model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | FLOPs\n",
      "------------------------------------------------------------------\n",
      "0 | backbone    | SwinTransformerV2 | 27.6 M | train | 0    \n",
      "1 | head_green  | Sequential        | 1.2 M  | train | 0    \n",
      "2 | head_clover | Sequential        | 1.2 M  | train | 0    \n",
      "3 | head_dead   | Sequential        | 1.2 M  | train | 0    \n",
      "4 | softplus    | Softplus          | 0      | train | 0    \n",
      "------------------------------------------------------------------\n",
      "31.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.2 M    Total params\n",
      "124.867   Total estimated model params size (MB)\n",
      "311       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  0.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:317: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|████████  | 4/5 [03:59<00:59,  0.02it/s, v_num=xb08, train_loss_step=1.49e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 29. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5/5 [04:25<00:00,  0.02it/s, v_num=xb08, train_loss_step=1.07e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5/5 [04:55<00:00,  0.02it/s, v_num=xb08, train_loss_step=1.07e+3, val_loss=1.56e+3, train_loss_epoch=1.84e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1561.585\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5/5 [04:58<00:00,  0.02it/s, v_num=xb08, train_loss_step=1.07e+3, val_loss=1.56e+3, train_loss_epoch=1.84e+3]\n",
      "\u001b[38;2;161;247;255m\n",
      "[2025-12-11 01:00:45]\n",
      "INFO: Loading best model from: C:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\notebooks\\kaggle\\checkpoints\\teacher\\fold0\\swinv2_tiny_window8_256-local_train[5]Folds_epochs1_bs64_gradacc1_lr2e-05_wd0.01_dr0.2_hr0.5-fold0-epoch=00-val_loss=1561.5847.ckpt\u001b[0m\n",
      "\u001b[38;2;161;247;255m\n",
      "[2025-12-11 01:00:46]\n",
      "INFO: Model initialized: backbone=swinv2_tiny_window8_256, feat_dim=768, combined_dim=1557\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:01<00:00,  1.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁█</td></tr><tr><td>train_loss_epoch</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▁█</td></tr><tr><td>val_loss</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_loss_epoch</td><td>1836.86902</td></tr><tr><td>trainer/global_step</td><td>5</td></tr><tr><td>val_loss</td><td>1561.58472</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swinv2_tiny_window8_256-local_train[5]Folds_epochs1_bs64_gradacc1_lr2e-05_wd0.01_dr0.2_hr0.5-fold0</strong> at: <a href='https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction/runs/g0urxb08' target=\"_blank\">https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction/runs/g0urxb08</a><br> View project at: <a href='https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction' target=\"_blank\">https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction</a><br>Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>wandb\\run-20251211_005530-g0urxb08\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1:\n",
      "  Train size: 285\n",
      "  Val size: 72\n",
      "Train batches: 5\n",
      "Val batches: 2\n",
      "Tabular features dimension: 21\n",
      "\u001b[38;2;161;247;255m\n",
      "[2025-12-11 01:01:39]\n",
      "INFO: Model initialized: backbone=swinv2_tiny_window8_256, feat_dim=768, combined_dim=1557\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\lightning_fabric\\connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb\\run-20251211_010139-71njhxun</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction/runs/71njhxun' target=\"_blank\">swinv2_tiny_window8_256-local_train[5]Folds_epochs1_bs64_gradacc1_lr2e-05_wd0.01_dr0.2_hr0.5-fold1</a></strong> to <a href='https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction' target=\"_blank\">https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction/runs/71njhxun' target=\"_blank\">https://wandb.ai/dmykhailov-kyiv-school-of-economics/csiro-image2biomass-prediction/runs/71njhxun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\model_summary\\model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name        | Type              | Params | Mode  | FLOPs\n",
      "------------------------------------------------------------------\n",
      "0 | backbone    | SwinTransformerV2 | 27.6 M | train | 0    \n",
      "1 | head_green  | Sequential        | 1.2 M  | train | 0    \n",
      "2 | head_clover | Sequential        | 1.2 M  | train | 0    \n",
      "3 | head_dead   | Sequential        | 1.2 M  | train | 0    \n",
      "4 | softplus    | Softplus          | 0      | train | 0    \n",
      "------------------------------------------------------------------\n",
      "31.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.2 M    Total params\n",
      "124.867   Total estimated model params size (MB)\n",
      "311       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "c:\\_GitHub\\CSIRO-Image2Biomass-Prediction\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:317: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Train on all folds\n",
    "fold_results = []\n",
    "\n",
    "for fold_id in range(N_FOLDS):\n",
    "    train_loader, val_loader = get_loaders(fold=fold_id, bs=BATCH_SIZE)\n",
    "    \n",
    "    model = BiomassTeacherModel(\n",
    "        backbone_name=MODEL,\n",
    "        tabular_dim=train_loader.dataset.tabular_features.shape[1],\n",
    "        num_targets=len(target_cols),\n",
    "        lr=LR,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        hidden_ratio=HIDDEN_RATIO,\n",
    "        dropout=DROPOUT_RATE\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',\n",
    "        dirpath=os.path.join(CHECKPOINTS_DIR, f'fold{fold_id}'),\n",
    "        filename=f'{DESCRIPTION_FULL}-fold{fold_id}' + '-{epoch:02d}-{val_loss:.4f}',\n",
    "        save_top_k=1,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        mode='min',\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    \n",
    "    # Logger\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=PROJECT_NAME,\n",
    "        name=f'{DESCRIPTION_FULL}-fold{fold_id}',\n",
    "        log_model='all'\n",
    "    )\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS,\n",
    "        accelerator=DEVICE.type,\n",
    "        precision=16 if torch.cuda.is_available() else 32,\n",
    "        accumulate_grad_batches=GRAD_ACCUM,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, lr_monitor],\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=10,\n",
    "        enable_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    # Load best checkpoint\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    logger.info(f\"Loading best model from: {best_model_path}\")\n",
    "    best_model = BiomassTeacherModel.load_from_checkpoint(best_model_path)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_result = trainer.validate(best_model, val_loader, verbose=False)\n",
    "    fold_results.append({\n",
    "        'fold': fold_id,\n",
    "        'val_loss': val_result[0]['val_loss']\n",
    "    })\n",
    "    \n",
    "    wandb_logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c9c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Summary\")\n",
    "print()\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "print(results_df)\n",
    "print(f\"Mean Val Loss: {results_df['val_loss'].mean():.4f} ± {results_df['val_loss'].std():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image2biomass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
