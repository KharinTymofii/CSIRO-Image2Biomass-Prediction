{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dafc480",
   "metadata": {},
   "source": [
    "# Distillation. Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bdd7d3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ff175635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1+cu128\n",
      "Device: NVIDIA GeForce RTX 5050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import cast\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import warnings\n",
    "from notebooks_config import setup_logging, CustomLogger\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba1c03c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;105;254;105m\n",
      "[2025-12-10 23:16:41]\n",
      "SUCCESS: Logging configured successfully âœ…\u001b[0m\n",
      "\u001b[38;2;105;254;105m\n",
      "[2025-12-10 23:16:41]\n",
      "SUCCESS: Logging configuration test completed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger = setup_logging(full_color=True, include_function=False)\n",
    "logger = cast(CustomLogger, logger)  # Type hinting\n",
    "logger.success(\"Logging configuration test completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b9504",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e402a80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (1071, 9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sample_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sampling_Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "State",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Species",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Pre_GSHH_NDVI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Height_Ave_cm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1e1c55f2-17ea-4698-887c-8a65724fd855",
       "rows": [
        [
         "0",
         "ID1011485656__Dry_Clover_g",
         "train/ID1011485656.jpg",
         "2015/9/4",
         "Tas",
         "Ryegrass_Clover",
         "0.62",
         "4.6667",
         "Dry_Clover_g",
         "0.0"
        ],
        [
         "1",
         "ID1011485656__Dry_Dead_g",
         "train/ID1011485656.jpg",
         "2015/9/4",
         "Tas",
         "Ryegrass_Clover",
         "0.62",
         "4.6667",
         "Dry_Dead_g",
         "31.9984"
        ],
        [
         "2",
         "ID1011485656__Dry_Green_g",
         "train/ID1011485656.jpg",
         "2015/9/4",
         "Tas",
         "Ryegrass_Clover",
         "0.62",
         "4.6667",
         "Dry_Green_g",
         "16.275"
        ],
        [
         "5",
         "ID1012260530__Dry_Clover_g",
         "train/ID1012260530.jpg",
         "2015/4/1",
         "NSW",
         "Lucerne",
         "0.55",
         "16.0",
         "Dry_Clover_g",
         "0.0"
        ],
        [
         "6",
         "ID1012260530__Dry_Dead_g",
         "train/ID1012260530.jpg",
         "2015/4/1",
         "NSW",
         "Lucerne",
         "0.55",
         "16.0",
         "Dry_Dead_g",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Sampling_Date</th>\n",
       "      <th>State</th>\n",
       "      <th>Species</th>\n",
       "      <th>Pre_GSHH_NDVI</th>\n",
       "      <th>Height_Ave_cm</th>\n",
       "      <th>target_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1011485656__Dry_Clover_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Clover_g</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1011485656__Dry_Dead_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Dead_g</td>\n",
       "      <td>31.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1011485656__Dry_Green_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Green_g</td>\n",
       "      <td>16.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID1012260530__Dry_Clover_g</td>\n",
       "      <td>train/ID1012260530.jpg</td>\n",
       "      <td>2015/4/1</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Lucerne</td>\n",
       "      <td>0.55</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>Dry_Clover_g</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID1012260530__Dry_Dead_g</td>\n",
       "      <td>train/ID1012260530.jpg</td>\n",
       "      <td>2015/4/1</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Lucerne</td>\n",
       "      <td>0.55</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>Dry_Dead_g</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id              image_path Sampling_Date State  \\\n",
       "0  ID1011485656__Dry_Clover_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "1    ID1011485656__Dry_Dead_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "2   ID1011485656__Dry_Green_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "5  ID1012260530__Dry_Clover_g  train/ID1012260530.jpg      2015/4/1   NSW   \n",
       "6    ID1012260530__Dry_Dead_g  train/ID1012260530.jpg      2015/4/1   NSW   \n",
       "\n",
       "           Species  Pre_GSHH_NDVI  Height_Ave_cm   target_name   target  \n",
       "0  Ryegrass_Clover           0.62         4.6667  Dry_Clover_g   0.0000  \n",
       "1  Ryegrass_Clover           0.62         4.6667    Dry_Dead_g  31.9984  \n",
       "2  Ryegrass_Clover           0.62         4.6667   Dry_Green_g  16.2750  \n",
       "5          Lucerne           0.55        16.0000  Dry_Clover_g   0.0000  \n",
       "6          Lucerne           0.55        16.0000    Dry_Dead_g   0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH_DATA = './kaggle/input/csiro-biomass'\n",
    "PATH_TRAIN_CSV = os.path.join(PATH_DATA, 'train.csv')\n",
    "PATH_TEST_CSV = os.path.join(PATH_DATA, 'test.csv')\n",
    "PATH_TRAIN_IMG = os.path.join(PATH_DATA, 'train')\n",
    "PATH_TEST_IMG = os.path.join(PATH_DATA, 'test')\n",
    "\n",
    "df = pd.read_csv(PATH_TRAIN_CSV)\n",
    "df = df[~df['target_name'].isin(['Dry_Total_g', 'GDM_g'])]  # Remove unneeded targets\n",
    "print(f\"Dataset size: {df.shape}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1285873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(357, 9)\n",
      "               image_path Sampling_Date State            Species  \\\n",
      "0  train/ID1011485656.jpg      2015/9/4   Tas    Ryegrass_Clover   \n",
      "1  train/ID1012260530.jpg      2015/4/1   NSW            Lucerne   \n",
      "2  train/ID1025234388.jpg      2015/9/1    WA  SubcloverDalkeith   \n",
      "3  train/ID1028611175.jpg     2015/5/18   Tas           Ryegrass   \n",
      "4  train/ID1035947949.jpg     2015/9/11   Tas           Ryegrass   \n",
      "\n",
      "   Height_Ave_cm  Pre_GSHH_NDVI  Dry_Clover_g  Dry_Dead_g  Dry_Green_g  \n",
      "0         4.6667           0.62        0.0000     31.9984      16.2750  \n",
      "1        16.0000           0.55        0.0000      0.0000       7.6000  \n",
      "2         1.0000           0.38        6.0500      0.0000       0.0000  \n",
      "3         5.0000           0.66        0.0000     30.9703      24.2376  \n",
      "4         3.5000           0.54        0.4343     23.2239      10.5261  \n"
     ]
    }
   ],
   "source": [
    "# pivot the dataframe to have one row per image with multiple target columns\n",
    "tabular_df = df.pivot_table(index=['image_path', 'Sampling_Date', 'State', 'Species', 'Height_Ave_cm', 'Pre_GSHH_NDVI'],\n",
    "                              columns='target_name', values='target', aggfunc='first').reset_index()\n",
    "tabular_df.columns.name = None  # remove the aggregation name\n",
    "print(tabular_df.shape)\n",
    "print(tabular_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c96a1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_path', 'Sampling_Date', 'State', 'Species', 'Height_Ave_cm', 'Pre_GSHH_NDVI', 'Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g']\n"
     ]
    }
   ],
   "source": [
    "print(tabular_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0220a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols  = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g']\n",
    "num_features = ['Height_Ave_cm', 'Pre_GSHH_NDVI']\n",
    "cat_features = ['Species', 'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b44b2e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features), # normalizing numeric features\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), cat_features) # OHE for categorical features\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdb7c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_data = preprocessor.fit_transform(tabular_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bd47682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(357, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.28520388, -0.24631873,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.81823967, -0.70706013,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.64220462, -1.82600352,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [-0.25275281,  0.01696207,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.39879723, -0.77288032,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tabular_data.shape)\n",
    "display(tabular_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbb541",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "413e7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassDataset(Dataset):\n",
    "    \"\"\"Dataset for biomass prediction with image + tabular features\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        df: pd.DataFrame,\n",
    "        tabular_features: np.ndarray,\n",
    "        target_cols: list[str],\n",
    "        img_dir: str,\n",
    "        transform: transforms.Compose | None = None,\n",
    "        is_test: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: DataFrame with image_id, image_path, and target columns\n",
    "            tabular_features: Preprocessed tabular features (shape: [n_samples, n_features])\n",
    "            target_cols: List of target column names\n",
    "            img_dir: Root directory for images\n",
    "            transform: torchvision transform pipeline\n",
    "            is_test: If True, targets are not expected in df\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tabular_features = tabular_features\n",
    "        self.target_cols = target_cols\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        assert len(self.df) == len(self.tabular_features), \\\n",
    "            f\"DataFrame length {len(self.df)} != tabular features length {len(self.tabular_features)}\"\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            dict with keys:\n",
    "                - 'left_image': tensor [C, H, W]\n",
    "                - 'right_image': tensor [C, H, W]\n",
    "                - 'tabular': tensor [n_features]\n",
    "                - 'targets': tensor [n_targets] (if not test)\n",
    "                - 'image_id': str\n",
    "        \"\"\"\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, row['image_path'].replace('train/', '').replace('test/', ''))\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Cannot load image: {img_path}\")\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Split into left and right patches\n",
    "        # Original image shape: [H, W, C] = [1000, 2000, 3]\n",
    "        h, w, c = image.shape\n",
    "        mid_w = w // 2\n",
    "        \n",
    "        left_patch = image[:, :mid_w, :]   # [1000, 1000, 3]\n",
    "        right_patch = image[:, mid_w:, :]  # [1000, 1000, 3]\n",
    "        \n",
    "        # Convert to PIL Image for torchvision transforms\n",
    "        left_pil = Image.fromarray(left_patch)\n",
    "        right_pil = Image.fromarray(right_patch)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            left_tensor = self.transform(left_pil)\n",
    "            right_tensor = self.transform(right_pil)\n",
    "        else:\n",
    "            left_tensor = transforms.ToTensor()(left_pil)\n",
    "            right_tensor = transforms.ToTensor()(right_pil)\n",
    "        \n",
    "        # Get tabular features\n",
    "        tabular = torch.tensor(self.tabular_features[idx], dtype=torch.float32)\n",
    "        \n",
    "        # Prepare output\n",
    "        output = {\n",
    "            'left_image': left_tensor,\n",
    "            'right_image': right_tensor,\n",
    "            'tabular': tabular,\n",
    "            'image_id': row['image_path'].split('/')[-1].replace('.jpg', '')\n",
    "        }\n",
    "        \n",
    "        # Add targets if not test\n",
    "        if not self.is_test:\n",
    "            targets = torch.tensor(\n",
    "                row[self.target_cols].values.astype(np.float32),\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            output['targets'] = targets\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "14e0673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_img_data_stat(df: pd.DataFrame):\n",
    "    \"\"\"Calculate mean and std of image data for normalization.\"\"\"\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    loader = tqdm(df['image_path'], desc=\"Calculating image stats\")\n",
    "    \n",
    "    for img_path in loader:\n",
    "        full_path = os.path.join(PATH_TRAIN_IMG, img_path.replace('train/', '').replace('test/', ''))\n",
    "        image = cv2.imread(full_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image / 255.0  # Normalize to [0, 1]\n",
    "        \n",
    "        means.append(np.mean(image, axis=(0, 1)))\n",
    "        stds.append(np.std(image, axis=(0, 1)))\n",
    "    \n",
    "    mean = np.mean(means, axis=0)\n",
    "    std = np.mean(stds, axis=0)\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4abf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean, train_std = calculate_img_data_stat(tabular_df)\n",
    "print(f\"Train Image Mean: {train_mean}, Std: {train_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "06c353b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each patch is 1000x1000, resize to 768x768 for vision transformers\n",
    "size = 768\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc5ef120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left image shape: torch.Size([3, 768, 768])\n",
      "Right image shape: torch.Size([3, 768, 768])\n",
      "Tabular shape: torch.Size([21])\n",
      "Targets shape: torch.Size([3])\n",
      "Image ID: ID1011485656\n",
      "Target values: tensor([ 0.0000, 31.9984, 16.2750])\n"
     ]
    }
   ],
   "source": [
    "# Create dataset instance\n",
    "train_dataset = BiomassDataset(\n",
    "    df=tabular_df,\n",
    "    tabular_features=tabular_data,\n",
    "    target_cols=target_cols,\n",
    "    img_dir=PATH_TRAIN_IMG,\n",
    "    transform=train_transform,\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "# Test it\n",
    "sample = train_dataset[0]\n",
    "print(f\"Left image shape: {sample['left_image'].shape}\")\n",
    "print(f\"Right image shape: {sample['right_image'].shape}\")\n",
    "print(f\"Tabular shape: {sample['tabular'].shape}\")\n",
    "print(f\"Targets shape: {sample['targets'].shape}\")\n",
    "print(f\"Image ID: {sample['image_id']}\")\n",
    "print(f\"Target values: {sample['targets']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd87b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image2biomass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
