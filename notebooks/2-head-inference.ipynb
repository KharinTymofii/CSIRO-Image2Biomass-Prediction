{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865c1bde",
   "metadata": {
    "papermill": {
     "duration": 0.004115,
     "end_time": "2025-12-11T19:12:20.041103",
     "exception": false,
     "start_time": "2025-12-11T19:12:20.036988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c0636",
   "metadata": {
    "papermill": {
     "duration": 0.003092,
     "end_time": "2025-12-11T19:12:20.047506",
     "exception": false,
     "start_time": "2025-12-11T19:12:20.044414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9197d4-e92c-41da-a2cd-af8eb7473d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:01:05.850499Z",
     "iopub.status.busy": "2025-12-15T20:01:05.849876Z",
     "iopub.status.idle": "2025-12-15T20:01:05.974373Z",
     "shell.execute_reply": "2025-12-15T20:01:05.973431Z",
     "shell.execute_reply.started": "2025-12-15T20:01:05.850471Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2head  csiro-biomass\n"
     ]
    }
   ],
   "source": [
    "!ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d89162-efeb-476c-9554-9e560bb36eb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:01:05.976390Z",
     "iopub.status.busy": "2025-12-15T20:01:05.976103Z",
     "iopub.status.idle": "2025-12-15T20:01:05.980803Z",
     "shell.execute_reply": "2025-12-15T20:01:05.980062Z",
     "shell.execute_reply.started": "2025-12-15T20:01:05.976368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IS_ENSEMBLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299f95a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:01:05.981695Z",
     "iopub.status.busy": "2025-12-15T20:01:05.981486Z",
     "iopub.status.idle": "2025-12-15T20:02:02.729195Z",
     "shell.execute_reply": "2025-12-15T20:02:02.728543Z",
     "shell.execute_reply.started": "2025-12-15T20:01:05.981656Z"
    },
    "papermill": {
     "duration": 18.334462,
     "end_time": "2025-12-11T19:12:38.385055",
     "exception": false,
     "start_time": "2025-12-11T19:12:20.050593",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-12-15 20:01:33.518600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765828893.882133      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765828893.997026      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.6.0+cu124\n",
      "Device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoConfig\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from transformers import Dinov2Model, Dinov2Config\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(\n",
    "    f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a1548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:02.731093Z",
     "iopub.status.busy": "2025-12-15T20:02:02.730614Z",
     "iopub.status.idle": "2025-12-15T20:02:03.289041Z",
     "shell.execute_reply": "2025-12-15T20:02:03.288162Z",
     "shell.execute_reply.started": "2025-12-15T20:02:02.731074Z"
    },
    "papermill": {
     "duration": 0.264771,
     "end_time": "2025-12-11T19:12:38.653430",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.388659",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        if not filename.endswith('.jpg'):\n",
    "            \n",
    "            print(os.path.join(dirname, filename))\n",
    "        # /kaggle/input/2head/pytorch/default/1/f1dinov2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"/kaggle/input/dinov2/pytorch/base/1/\", local_files_only=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13369e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:03.308445Z",
     "iopub.status.busy": "2025-12-15T20:02:03.308201Z",
     "iopub.status.idle": "2025-12-15T20:02:03.706895Z",
     "shell.execute_reply": "2025-12-15T20:02:03.705948Z",
     "shell.execute_reply.started": "2025-12-15T20:02:03.308427Z"
    },
    "papermill": {
     "duration": 0.246526,
     "end_time": "2025-12-11T19:12:38.925434",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.678908",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NUM_WORKERS: 0\n",
      "\n",
      "Tesla T4\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)\n",
    "print('NUM_WORKERS:', NUM_WORKERS)\n",
    "print()\n",
    "\n",
    "# Additional Info when using cuda\n",
    "if DEVICE.type == 'cuda':\n",
    "    # clean GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # torch.set_float32_matmul_precision('high')\n",
    "\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3, 1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d6f31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:03.290356Z",
     "iopub.status.busy": "2025-12-15T20:02:03.289962Z",
     "iopub.status.idle": "2025-12-15T20:02:03.307399Z",
     "shell.execute_reply": "2025-12-15T20:02:03.306787Z",
     "shell.execute_reply.started": "2025-12-15T20:02:03.290300Z"
    },
    "papermill": {
     "duration": 0.018698,
     "end_time": "2025-12-11T19:12:38.675573",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.656875",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESCRIPTION_FULL: facebook_dinov2-base-kaggle_train[5]Folds_log_fusion-gating_epochs25_bs16_gradacc1_lr0.0001_wd0.05_dr0.3_hr0.5\n",
      "Effective batch size: 16\n"
     ]
    }
   ],
   "source": [
    "cpu_count = os.cpu_count()\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "LR = 1e-4\n",
    "EPOCHS = 25\n",
    "N_FOLDS = 5\n",
    "GRAD_ACCUM = 1\n",
    "BATCH_SIZE = 16\n",
    "DROPOUT_RATE = 0.3\n",
    "# Weight for distillation loss\n",
    "# Loss = DISTILL_ALPHA * Distillation_Loss + (1 - DISTILL_ALPHA) * Hard_Loss\n",
    "DISTILL_ALPHA = 0.5\n",
    "WEIGHT_DECAY = 0.05\n",
    "HIDDEN_RATIO = 0.5\n",
    "TRAIN_SPLIT_RATIO = 0.02  # Used if N_FOLDS = 0\n",
    "\n",
    "MODEL = 'facebook/dinov2-base'\n",
    "CHECKPOINTS_DIR = f\"/kaggle/input/2head/pytorch/default/1/\"\n",
    "WEIGHTS_PATH = f\"{CHECKPOINTS_DIR}{MODEL.replace('/', '_')}.pth\"\n",
    "PROJECT_NAME = \"csiro-image2biomass-prediction\"\n",
    "# Whether to use OOF soft targets or 100% ensemble soft targets\n",
    "USE_OOF_SOFT_TARGETS = False\n",
    "\n",
    "# Each patch is 1000x1000, resize to 768x768 for vision transformers\n",
    "SIZE = 768\n",
    "USE_LOG_TARGET = True     # Whether to use log1p transformation on target variable\n",
    "FUSION_METHOD = 'gating'  # ('concat', 'mean', 'max') OR 'gating'\n",
    "\n",
    "DESCRIPTION = \"kaggle\" + \\\n",
    "    (f\"_train{TRAIN_SPLIT_RATIO}\" if N_FOLDS == 0 else f\"_train[{N_FOLDS}]Folds\") + (\n",
    "        f\"_log\" if USE_LOG_TARGET else \"\") + f\"_fusion-{FUSION_METHOD}\"\n",
    "DESCRIPTION_FULL = MODEL.replace('/', '_') + \"-\" + DESCRIPTION + \\\n",
    "    f\"_epochs{EPOCHS}_bs{BATCH_SIZE}_gradacc{GRAD_ACCUM}_lr{LR}_wd{WEIGHT_DECAY}_dr{DROPOUT_RATE}_hr{HIDDEN_RATIO}\"\n",
    "SUBMISSION_NAME = f\"{DESCRIPTION_FULL}_submission.csv\"\n",
    "SUBMISSION_ENSEMBLE_NAME = f\"{DESCRIPTION_FULL}_ensemble_submission.csv\"\n",
    "SUBMISSION_MSG = DESCRIPTION_FULL.replace(\"_\", \" \")\n",
    "\n",
    "SEED = 1488\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "pl.seed_everything(SEED)\n",
    "\n",
    "print(\"DESCRIPTION_FULL:\", DESCRIPTION_FULL)\n",
    "print(f\"Effective batch size: {BATCH_SIZE * GRAD_ACCUM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0baaac",
   "metadata": {
    "papermill": {
     "duration": 0.003521,
     "end_time": "2025-12-11T19:12:38.932551",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.929030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d676db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:03.708149Z",
     "iopub.status.busy": "2025-12-15T20:02:03.707896Z",
     "iopub.status.idle": "2025-12-15T20:02:03.731255Z",
     "shell.execute_reply": "2025-12-15T20:02:03.730526Z",
     "shell.execute_reply.started": "2025-12-15T20:02:03.708131Z"
    },
    "papermill": {
     "duration": 0.010274,
     "end_time": "2025-12-11T19:12:38.946120",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.935846",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Dry_Clover_g\",\n",
    "    \"Dry_Dead_g\",\n",
    "    \"Dry_Green_g\",\n",
    "    \"Dry_Total_g\",\n",
    "    \"GDM_g\"\n",
    "]\n",
    "\n",
    "weights = {\n",
    "    'Dry_Green_g': 0.1,\n",
    "    'Dry_Dead_g': 0.1,\n",
    "    'Dry_Clover_g': 0.1,\n",
    "    'GDM_g': 0.2,\n",
    "    'Dry_Total_g': 0.5,\n",
    "}\n",
    "\n",
    "\n",
    "def competition_metric(y_true, y_pred) -> float:\n",
    "    \"\"\"Function to calculate the competition's official evaluation metric (weighted R2 score).\"\"\"\n",
    "    weights_array = np.array([weights[l] for l in labels])\n",
    "\n",
    "    # Align with this calculation method\n",
    "    y_weighted_mean = np.average(y_true, weights=weights_array, axis=1).mean()\n",
    "\n",
    "    # For ss_res and ss_tot, also take the weighted average on axis=1, then the mean of the result\n",
    "    ss_res = np.average((y_true - y_pred)**2,\n",
    "                        weights=weights_array, axis=1).mean()\n",
    "    ss_tot = np.average((y_true - y_weighted_mean)**2,\n",
    "                        weights=weights_array, axis=1).mean()\n",
    "\n",
    "    return 1 - ss_res / ss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da81bbf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:03.732468Z",
     "iopub.status.busy": "2025-12-15T20:02:03.732227Z",
     "iopub.status.idle": "2025-12-15T20:02:03.755457Z",
     "shell.execute_reply": "2025-12-15T20:02:03.754826Z",
     "shell.execute_reply.started": "2025-12-15T20:02:03.732442Z"
    },
    "papermill": {
     "duration": 0.012976,
     "end_time": "2025-12-11T19:12:38.962524",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.949548",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BiomassTeacherModelPatches(pl.LightningModule):\n",
    "    \"\"\"Dual-head teacher model for image-only inference (no tabular required).\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_name: str = 'facebook/dinov2-base',\n",
    "        tabular_dim: int = 0,              # default to 0 for inference\n",
    "        num_targets: int = 3,\n",
    "        lr: float = 1e-4,\n",
    "        weight_decay: float = 1e-5,\n",
    "        hidden_ratio: float = 0.5,\n",
    "        dropout: float = 0.2,\n",
    "        fusion_method: str = 'gating',\n",
    "        use_log_target: bool = True,\n",
    "        tabular_dropout_prob: float = 0.3,\n",
    "        lambda_cons: float = 0.5,\n",
    "        pretrained_backbone: bool = False,  # force offline init\n",
    "        backbone_weights_path: str | None = None,\n",
    "        image_size: int = 768,              # ensure config fits intended size\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Offline backbone init (no internet)\n",
    "        try:\n",
    "            config = Dinov2Config.from_pretrained(backbone_name, local_files_only=True)\n",
    "            # Override image size in config for our inference\n",
    "            config.image_size = image_size\n",
    "        except Exception:\n",
    "            config = Dinov2Config()\n",
    "            config.image_size = image_size\n",
    "\n",
    "        self.backbone = Dinov2Model(config)\n",
    "        if backbone_weights_path and os.path.exists(backbone_weights_path):\n",
    "            sd = torch.load(backbone_weights_path, map_location='cpu')\n",
    "            # Load with strict=False to ignore position_embeddings size mismatch\n",
    "            missing, unexpected = self.backbone.load_state_dict(sd, strict=False)\n",
    "            if missing:\n",
    "                print(f\"[Backbone] Missing keys: {len(missing)}\")\n",
    "            if unexpected:\n",
    "                print(f\"[Backbone] Unexpected keys: {len(unexpected)}\")\n",
    "\n",
    "        self.hidden_dim = self.backbone.config.hidden_size\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.fusion_method = fusion_method\n",
    "        self.use_log_target = use_log_target\n",
    "        self.tabular_dropout_prob = tabular_dropout_prob\n",
    "        self.lambda_cons = lambda_cons\n",
    "        self.prediction_mode = 'img'\n",
    "\n",
    "        hidden_size = max(32, int(self.hidden_dim * hidden_ratio))\n",
    "\n",
    "        def make_patch_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.hidden_dim, hidden_size),\n",
    "                nn.LayerNorm(hidden_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_size, 1)\n",
    "            )\n",
    "\n",
    "        # Image heads\n",
    "        self.img_head_green = make_patch_head()\n",
    "        self.img_head_clover = make_patch_head()\n",
    "        self.img_head_dead = make_patch_head()\n",
    "\n",
    "        # Keep privileged heads for checkpoint compatibility\n",
    "        self.priv_head_green = make_patch_head()\n",
    "        self.priv_head_clover = make_patch_head()\n",
    "        self.priv_head_dead = make_patch_head()\n",
    "\n",
    "        # Do NOT build tabular layers if tabular_dim == 0\n",
    "        self.has_tabular = tabular_dim > 0\n",
    "        if self.has_tabular and self.fusion_method == 'gating':\n",
    "            self.tabular_gate = nn.Sequential(\n",
    "                nn.Linear(tabular_dim, hidden_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(hidden_size, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        elif self.has_tabular and self.fusion_method == 'concat':\n",
    "            self.fusion_layer = nn.Sequential(\n",
    "                nn.Linear(3 + tabular_dim, hidden_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_size, 3)\n",
    "            )\n",
    "\n",
    "    def forward(self, batch: dict):\n",
    "        # Forward through DINOv2 for both patches\n",
    "        left_outputs = self.backbone(batch['left_image'])\n",
    "        left_patches = left_outputs.last_hidden_state[:, 1:, :]\n",
    "        right_outputs = self.backbone(batch['right_image'])\n",
    "        right_patches = right_outputs.last_hidden_state[:, 1:, :]\n",
    "        all_patches = torch.cat([left_patches, right_patches], dim=1)\n",
    "\n",
    "        # Image-only predictions\n",
    "        img_green = self.img_head_green(all_patches).mean(dim=1).squeeze(1)\n",
    "        img_clover = self.img_head_clover(all_patches).mean(dim=1).squeeze(1)\n",
    "        img_dead = self.img_head_dead(all_patches).mean(dim=1).squeeze(1)\n",
    "\n",
    "        # Privileged predictions (kept for checkpoint compatibility)\n",
    "        priv_green = self.priv_head_green(all_patches).mean(dim=1).squeeze(1)\n",
    "        priv_clover = self.priv_head_clover(all_patches).mean(dim=1).squeeze(1)\n",
    "        priv_dead = self.priv_head_dead(all_patches).mean(dim=1).squeeze(1)\n",
    "\n",
    "        # No tabular fusion in inference if tabular_dim == 0\n",
    "        if self.has_tabular:\n",
    "            tabular = batch.get('tabular', None)\n",
    "            if tabular is None:\n",
    "                tabular = torch.zeros(img_green.size(0),\n",
    "                                      self.tabular_gate[0].in_features\n",
    "                                      if hasattr(self, 'tabular_gate') else 0,\n",
    "                                      device=img_green.device)\n",
    "            if tabular.numel() > 0:\n",
    "                if self.fusion_method == 'gating' and hasattr(self, 'tabular_gate'):\n",
    "                    gate = self.tabular_gate(tabular).squeeze(1)\n",
    "                    priv_green = priv_green * gate\n",
    "                    priv_clover = priv_clover * gate\n",
    "                    priv_dead = priv_dead * gate\n",
    "                elif self.fusion_method == 'concat' and hasattr(self, 'fusion_layer'):\n",
    "                    combined = torch.cat([\n",
    "                        priv_green.unsqueeze(1),\n",
    "                        priv_clover.unsqueeze(1),\n",
    "                        priv_dead.unsqueeze(1),\n",
    "                        tabular\n",
    "                    ], dim=1)\n",
    "                    output = self.fusion_layer(combined)\n",
    "                    priv_green, priv_clover, priv_dead = output[:, 0], output[:, 1], output[:, 2]\n",
    "\n",
    "        return (img_green, img_clover, img_dead), (priv_green, priv_clover, priv_dead)\n",
    "\n",
    "    def predict_step(self, batch: dict, batch_idx: int = 0) -> torch.Tensor:\n",
    "        img_pred, priv_pred = self(batch)\n",
    "        if self.prediction_mode == 'img':\n",
    "            green, clover, dead = img_pred\n",
    "        else:\n",
    "            green, clover, dead = priv_pred\n",
    "\n",
    "        preds = torch.stack([clover, dead, green], dim=1)\n",
    "        if self.use_log_target:\n",
    "            preds = torch.expm1(preds)\n",
    "        preds = torch.clamp(preds, min=0.0)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc59dd50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:03.756763Z",
     "iopub.status.busy": "2025-12-15T20:02:03.756461Z",
     "iopub.status.idle": "2025-12-15T20:02:06.900388Z",
     "shell.execute_reply": "2025-12-15T20:02:06.899731Z",
     "shell.execute_reply.started": "2025-12-15T20:02:03.756733Z"
    },
    "papermill": {
     "duration": 1.701985,
     "end_time": "2025-12-11T19:12:40.694624",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.992639",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading backbone weights from: /kaggle/input/2head/pytorch/default/1/facebook_dinov2-base.pth\n",
      "Loading default Dinov2Config (offline)\n"
     ]
    }
   ],
   "source": [
    "# Load config and backbone offline (no internet)\n",
    "try:\n",
    "\n",
    "    config = Dinov2Config.from_pretrained(MODEL, local_files_only=True)\n",
    "    print(f\"Warning: {WEIGHTS_PATH} not found, using random initialization\")\n",
    "\n",
    "except Exception:\n",
    "    if os.path.exists(WEIGHTS_PATH):\n",
    "\n",
    "        print(f\"Loading backbone weights from: {WEIGHTS_PATH}\")\n",
    "        config = Dinov2Config()\n",
    "        config.image_size = 518\n",
    "        temp_backbone = Dinov2Model(config=config)\n",
    "        print(\"Loading default Dinov2Config (offline)\")\n",
    "        state_dict = torch.load(WEIGHTS_PATH, map_location='cpu')\n",
    "        temp_backbone.load_state_dict(state_dict, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da4ad65e-8420-4dbd-9733-5bdd3864d4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:06.903684Z",
     "iopub.status.busy": "2025-12-15T20:02:06.903360Z",
     "iopub.status.idle": "2025-12-15T20:02:06.910116Z",
     "shell.execute_reply": "2025-12-15T20:02:06.909368Z",
     "shell.execute_reply.started": "2025-12-15T20:02:06.903646Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dinov2Config {\n",
       "  \"apply_layernorm\": true,\n",
       "  \"attention_probs_dropout_prob\": 0.0,\n",
       "  \"drop_path_rate\": 0.0,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.0,\n",
       "  \"hidden_size\": 768,\n",
       "  \"image_size\": 518,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_eps\": 1e-06,\n",
       "  \"layerscale_value\": 1.0,\n",
       "  \"mlp_ratio\": 4,\n",
       "  \"model_type\": \"dinov2\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_channels\": 3,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"out_features\": [\n",
       "    \"stage12\"\n",
       "  ],\n",
       "  \"out_indices\": [\n",
       "    12\n",
       "  ],\n",
       "  \"patch_size\": 14,\n",
       "  \"qkv_bias\": true,\n",
       "  \"reshape_hidden_states\": true,\n",
       "  \"stage_names\": [\n",
       "    \"stem\",\n",
       "    \"stage1\",\n",
       "    \"stage2\",\n",
       "    \"stage3\",\n",
       "    \"stage4\",\n",
       "    \"stage5\",\n",
       "    \"stage6\",\n",
       "    \"stage7\",\n",
       "    \"stage8\",\n",
       "    \"stage9\",\n",
       "    \"stage10\",\n",
       "    \"stage11\",\n",
       "    \"stage12\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.53.3\",\n",
       "  \"use_mask_token\": true,\n",
       "  \"use_swiglu_ffn\": false\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20603376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:06.911204Z",
     "iopub.status.busy": "2025-12-15T20:02:06.910928Z",
     "iopub.status.idle": "2025-12-15T20:02:06.936481Z",
     "shell.execute_reply": "2025-12-15T20:02:06.935714Z",
     "shell.execute_reply.started": "2025-12-15T20:02:06.911165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # save model weights to file\n",
    "# torch.save(temp_backbone.state_dict(), WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d676fd6-f071-4fb8-a24c-99e63cc476f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:06.937326Z",
     "iopub.status.busy": "2025-12-15T20:02:06.937157Z",
     "iopub.status.idle": "2025-12-15T20:02:06.951301Z",
     "shell.execute_reply": "2025-12-15T20:02:06.950708Z",
     "shell.execute_reply.started": "2025-12-15T20:02:06.937311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs_size = config.image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6be3cb04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:06.952592Z",
     "iopub.status.busy": "2025-12-15T20:02:06.952117Z",
     "iopub.status.idle": "2025-12-15T20:02:06.965959Z",
     "shell.execute_reply": "2025-12-15T20:02:06.965320Z",
     "shell.execute_reply.started": "2025-12-15T20:02:06.952574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1586a378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:06.966932Z",
     "iopub.status.busy": "2025-12-15T20:02:06.966738Z",
     "iopub.status.idle": "2025-12-15T20:02:06.981059Z",
     "shell.execute_reply": "2025-12-15T20:02:06.980358Z",
     "shell.execute_reply.started": "2025-12-15T20:02:06.966918Z"
    },
    "papermill": {
     "duration": 0.280794,
     "end_time": "2025-12-11T19:12:40.979953",
     "exception": false,
     "start_time": "2025-12-11T19:12:40.699159",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone expected input size: 518, using SIZE=518\n",
      "Backbone expected mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]\n"
     ]
    }
   ],
   "source": [
    "# SIZE = inputs_size\n",
    "SIZE = inputs_size\n",
    "print(f\"Backbone expected input size: {inputs_size}, using SIZE={SIZE}\")\n",
    "print(f\"Backbone expected mean: {mean}, std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51858071-5d59-400d-95a2-426172c8f940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:06.982224Z",
     "iopub.status.busy": "2025-12-15T20:02:06.981783Z",
     "iopub.status.idle": "2025-12-15T20:02:09.046825Z",
     "shell.execute_reply": "2025-12-15T20:02:09.046053Z",
     "shell.execute_reply.started": "2025-12-15T20:02:06.982201Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# Get backbone output dimension\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(1, 3, SIZE, SIZE)\n",
    "    outputs = temp_backbone(dummy)\n",
    "    feat_dim = outputs.last_hidden_state.sum(\n",
    "        dim=1).shape[1]  # Average pooling\n",
    "    print(feat_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ad7904b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.047985Z",
     "iopub.status.busy": "2025-12-15T20:02:09.047662Z",
     "iopub.status.idle": "2025-12-15T20:02:09.052548Z",
     "shell.execute_reply": "2025-12-15T20:02:09.051529Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.047959Z"
    },
    "papermill": {
     "duration": 0.009317,
     "end_time": "2025-12-11T19:12:40.993095",
     "exception": false,
     "start_time": "2025-12-11T19:12:40.983778",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "student_val_transform = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f57baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.053763Z",
     "iopub.status.busy": "2025-12-15T20:02:09.053489Z",
     "iopub.status.idle": "2025-12-15T20:02:09.070083Z",
     "shell.execute_reply": "2025-12-15T20:02:09.069446Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.053736Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# TTA helpers\n",
    "TTA_TYPES = ['id', 'hflip', 'vflip', 'hvflip']\n",
    "\n",
    "\n",
    "def apply_tta(left: torch.Tensor, right: torch.Tensor, tta: str) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Apply simple flip-based TTA to both patches.\"\"\"\n",
    "    if tta == 'hflip':\n",
    "        return torch.flip(left, dims=[2]), torch.flip(right, dims=[2])\n",
    "    if tta == 'vflip':\n",
    "        return torch.flip(left, dims=[1]), torch.flip(right, dims=[1])\n",
    "    if tta == 'hvflip':\n",
    "        return torch.flip(left, dims=[1, 2]), torch.flip(right, dims=[1, 2])\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a5a5df0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.071670Z",
     "iopub.status.busy": "2025-12-15T20:02:09.071012Z",
     "iopub.status.idle": "2025-12-15T20:02:09.086496Z",
     "shell.execute_reply": "2025-12-15T20:02:09.085617Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.071632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def stack_targets_from_preds(preds_3: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Given [B,3] (clover, dead, green) produce [B,5] ordered targets.\"\"\"\n",
    "    clover = preds_3[:, 0]\n",
    "    dead = preds_3[:, 1]\n",
    "    green = preds_3[:, 2]\n",
    "    total = green + dead + clover\n",
    "    gdm = clover + green\n",
    "    return torch.stack([clover, dead, green, total, gdm], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac2c6e1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.087708Z",
     "iopub.status.busy": "2025-12-15T20:02:09.087386Z",
     "iopub.status.idle": "2025-12-15T20:02:09.107665Z",
     "shell.execute_reply": "2025-12-15T20:02:09.107010Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.087681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_model_batch(model: BiomassTeacherModelPatches, batch: dict, tta_types: list[str]) -> torch.Tensor:\n",
    "    \"\"\"Run model over TTA variants and average. Returns [B,5].\"\"\"\n",
    "    model_preds = []\n",
    "    for tta in tta_types:\n",
    "        left_t, right_t = apply_tta(\n",
    "            batch['left_image'], batch['right_image'], tta)\n",
    "        tta_batch = {\n",
    "            'left_image': left_t,\n",
    "            'right_image': right_t,\n",
    "            'tabular': batch['tabular'],\n",
    "        }\n",
    "        preds_3 = model.predict_step(tta_batch, 0)  # [B,3]\n",
    "        model_preds.append(stack_targets_from_preds(preds_3))\n",
    "    return torch.stack(model_preds, dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b494fd8",
   "metadata": {
    "papermill": {
     "duration": 0.003342,
     "end_time": "2025-12-11T19:12:40.999896",
     "exception": false,
     "start_time": "2025-12-11T19:12:40.996554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c97fc78c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.108855Z",
     "iopub.status.busy": "2025-12-15T20:02:09.108541Z",
     "iopub.status.idle": "2025-12-15T20:02:09.123920Z",
     "shell.execute_reply": "2025-12-15T20:02:09.123336Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.108831Z"
    },
    "papermill": {
     "duration": 0.008328,
     "end_time": "2025-12-11T19:12:41.012015",
     "exception": false,
     "start_time": "2025-12-11T19:12:41.003687",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PATH_DATA = '/kaggle/input/csiro-biomass'\n",
    "STUDENT_MODELS_DIR = CHECKPOINTS_DIR\n",
    "PATH_TEST_CSV = os.path.join(PATH_DATA, 'test.csv')\n",
    "PATH_TEST_IMG = os.path.join(PATH_DATA, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14d08303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.124891Z",
     "iopub.status.busy": "2025-12-15T20:02:09.124652Z",
     "iopub.status.idle": "2025-12-15T20:02:09.199613Z",
     "shell.execute_reply": "2025-12-15T20:02:09.198728Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.124874Z"
    },
    "papermill": {
     "duration": 0.041627,
     "end_time": "2025-12-11T19:12:41.057105",
     "exception": false,
     "start_time": "2025-12-11T19:12:41.015478",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 1\n",
      "              image_path                   sample_id   target_name\n",
      "0  test/ID1001187975.jpg  ID1001187975__Dry_Clover_g  Dry_Clover_g\n"
     ]
    }
   ],
   "source": [
    "# Load test CSV\n",
    "test_df = pd.read_csv(PATH_TEST_CSV)\n",
    "test_df = test_df[~test_df['target_name'].isin(['Dry_Total_g', 'GDM_g'])]\n",
    "\n",
    "# Pivot to one row per image\n",
    "test_pivot = test_df.pivot_table(\n",
    "    index='image_path',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "print(f\"Test set size: {len(test_pivot)}\")\n",
    "print(test_pivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a254b7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.200831Z",
     "iopub.status.busy": "2025-12-15T20:02:09.200523Z",
     "iopub.status.idle": "2025-12-15T20:02:09.205623Z",
     "shell.execute_reply": "2025-12-15T20:02:09.204875Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.200801Z"
    },
    "papermill": {
     "duration": 4.678651,
     "end_time": "2025-12-11T19:12:45.739256",
     "exception": false,
     "start_time": "2025-12-11T19:12:41.060605",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Checkpoint discovery and loading\n",
    "def parse_metric_from_filename(filename: str) -> float:\n",
    "    \"\"\"Extract val_comp_metric_img from filename like ...val_comp_metric_img=0.7129.ckpt.\"\"\"\n",
    "    try:\n",
    "        metric_part = filename.split('val_comp_metric_img=')[-1]\n",
    "        return float(metric_part.replace('.ckpt', ''))\n",
    "    except Exception:\n",
    "        return -float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "795f1792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.207244Z",
     "iopub.status.busy": "2025-12-15T20:02:09.206468Z",
     "iopub.status.idle": "2025-12-15T20:02:09.222477Z",
     "shell.execute_reply": "2025-12-15T20:02:09.221876Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.207224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_student_model(ckpt_path: str, backbone_weights_path: str | None = None) -> BiomassTeacherModelPatches:\n",
    "    \"\"\"Load model from checkpoint offline and move to DEVICE.\"\"\"\n",
    "    checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "    hparams = checkpoint.get('hyper_parameters', {})\n",
    "\n",
    "    model = BiomassTeacherModelPatches(\n",
    "        backbone_name=hparams.get('backbone_name', MODEL),\n",
    "        tabular_dim=0,  # force 0 - no tabular inference\n",
    "        num_targets=hparams.get('num_targets', 3),\n",
    "        lr=hparams.get('lr', LR),\n",
    "        weight_decay=hparams.get('weight_decay', WEIGHT_DECAY),\n",
    "        hidden_ratio=hparams.get('hidden_ratio', HIDDEN_RATIO),\n",
    "        dropout=hparams.get('dropout', DROPOUT_RATE),\n",
    "        fusion_method=hparams.get('fusion_method', FUSION_METHOD),\n",
    "        use_log_target=hparams.get('use_log_target', USE_LOG_TARGET),\n",
    "        tabular_dropout_prob=hparams.get('tabular_dropout_prob', 0.0),\n",
    "        lambda_cons=hparams.get('lambda_cons', 0.0),\n",
    "        pretrained_backbone=False,\n",
    "        backbone_weights_path=backbone_weights_path,\n",
    "        image_size=SIZE,\n",
    "    )\n",
    "    model.prediction_mode = 'img'\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Load model heads with strict=False\n",
    "    missing_keys, unexpected_keys = model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "    if missing_keys:\n",
    "        print(f\"[Model] Missing keys: {len(missing_keys)}\")\n",
    "    if unexpected_keys:\n",
    "        print(f\"[Model] Unexpected keys: {len(unexpected_keys)}\")\n",
    "        print(unexpected_keys)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e8fccc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.223561Z",
     "iopub.status.busy": "2025-12-15T20:02:09.223305Z",
     "iopub.status.idle": "2025-12-15T20:02:09.243724Z",
     "shell.execute_reply": "2025-12-15T20:02:09.242949Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.223542Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 student checkpoints:\n",
      "  - f0dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold0-epoch23-val_loss_img0.0000-val_comp_metric_img0.7129.ckpt\n",
      "  - f1dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold1-epoch24-val_loss_img0.0000-val_comp_metric_img0.726.ckpt\n",
      "  - f2dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold2-epoch28-val_loss_img0.0000-val_comp_metric_img0.773.ckpt\n",
      "  - f3dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold3-epoch25-val_loss_img0.0000-val_comp_metric_img0.725.ckpt\n",
      "  - f4dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold4-epoch26-val_loss_img0.0000-val_comp_metric_img0.7169.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Discover fold checkpoints and best overall\n",
    "ckpt_files = sorted([\n",
    "    f for f in os.listdir(STUDENT_MODELS_DIR) if f.endswith('.ckpt')\n",
    "])\n",
    "print(f\"Found {len(ckpt_files)} student checkpoints:\")\n",
    "for f in ckpt_files:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dff816d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.244812Z",
     "iopub.status.busy": "2025-12-15T20:02:09.244504Z",
     "iopub.status.idle": "2025-12-15T20:02:09.259762Z",
     "shell.execute_reply": "2025-12-15T20:02:09.258943Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.244794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Select 5 folds: filenames starting with f{fold}\n",
    "fold_ckpts = []\n",
    "for fold_id in range(N_FOLDS):\n",
    "    candidates = [f for f in ckpt_files if f.startswith(f\"f{fold_id}\")]\n",
    "    if not candidates:\n",
    "        continue\n",
    "    # pick best metric per fold\n",
    "    candidates.sort(key=parse_metric_from_filename, reverse=True)\n",
    "    fold_ckpts.append(os.path.join(STUDENT_MODELS_DIR, candidates[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6e10f33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.261004Z",
     "iopub.status.busy": "2025-12-15T20:02:09.260724Z",
     "iopub.status.idle": "2025-12-15T20:02:09.284549Z",
     "shell.execute_reply": "2025-12-15T20:02:09.283737Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.260981Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected fold checkpoints:\n",
      "  f0dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold0-epoch23-val_loss_img0.0000-val_comp_metric_img0.7129.ckpt\n",
      "  f1dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold1-epoch24-val_loss_img0.0000-val_comp_metric_img0.726.ckpt\n",
      "  f2dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold2-epoch28-val_loss_img0.0000-val_comp_metric_img0.773.ckpt\n",
      "  f3dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold3-epoch25-val_loss_img0.0000-val_comp_metric_img0.725.ckpt\n",
      "  f4dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold4-epoch26-val_loss_img0.0000-val_comp_metric_img0.7169.ckpt\n",
      "Best checkpoint: f0dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold0-epoch23-val_loss_img0.0000-val_comp_metric_img0.7129.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Best overall by metric\n",
    "best_ckpt = None\n",
    "if ckpt_files:\n",
    "    best_ckpt = os.path.join(\n",
    "        STUDENT_MODELS_DIR,\n",
    "        sorted(ckpt_files, key=parse_metric_from_filename, reverse=True)[0]\n",
    "    )\n",
    "\n",
    "print(\"Selected fold checkpoints:\")\n",
    "for p in fold_ckpts:\n",
    "    print(f\"  {os.path.basename(p)}\")\n",
    "print(\n",
    "    f\"Best checkpoint: {os.path.basename(best_ckpt) if best_ckpt else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "480e90a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:09.286915Z",
     "iopub.status.busy": "2025-12-15T20:02:09.285528Z",
     "iopub.status.idle": "2025-12-15T20:02:46.853028Z",
     "shell.execute_reply": "2025-12-15T20:02:46.852154Z",
     "shell.execute_reply.started": "2025-12-15T20:02:09.286872Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading fold model: f0dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold0-epoch23-val_loss_img0.0000-val_comp_metric_img0.7129.ckpt\n",
      "[Model] Unexpected keys: 4\n",
      "['tabular_gate.0.weight', 'tabular_gate.0.bias', 'tabular_gate.2.weight', 'tabular_gate.2.bias']\n",
      "\n",
      "Loading fold model: f1dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold1-epoch24-val_loss_img0.0000-val_comp_metric_img0.726.ckpt\n",
      "[Model] Unexpected keys: 4\n",
      "['tabular_gate.0.weight', 'tabular_gate.0.bias', 'tabular_gate.2.weight', 'tabular_gate.2.bias']\n",
      "\n",
      "Loading fold model: f2dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold2-epoch28-val_loss_img0.0000-val_comp_metric_img0.773.ckpt\n",
      "[Model] Unexpected keys: 4\n",
      "['tabular_gate.0.weight', 'tabular_gate.0.bias', 'tabular_gate.2.weight', 'tabular_gate.2.bias']\n",
      "\n",
      "Loading fold model: f3dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold3-epoch25-val_loss_img0.0000-val_comp_metric_img0.725.ckpt\n",
      "[Model] Unexpected keys: 4\n",
      "['tabular_gate.0.weight', 'tabular_gate.0.bias', 'tabular_gate.2.weight', 'tabular_gate.2.bias']\n",
      "\n",
      "Loading fold model: f4dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold4-epoch26-val_loss_img0.0000-val_comp_metric_img0.7169.ckpt\n",
      "[Model] Unexpected keys: 4\n",
      "['tabular_gate.0.weight', 'tabular_gate.0.bias', 'tabular_gate.2.weight', 'tabular_gate.2.bias']\n",
      "\n",
      "Loading best model: f0dinov2-base-local_train(5)Folds_log_fusion-gating_epochs30_bs4_gradacc4_lr3e-05_wd0.05_dr0.2_hr0.5-fold0-epoch23-val_loss_img0.0000-val_comp_metric_img0.7129.ckpt\n",
      "[Model] Unexpected keys: 4\n",
      "['tabular_gate.0.weight', 'tabular_gate.0.bias', 'tabular_gate.2.weight', 'tabular_gate.2.bias']\n",
      "\n",
      "Successfully loaded 5 student models\n",
      "Ready for offline inference on Kaggle!\n"
     ]
    }
   ],
   "source": [
    "# Load models WITHOUT internet (offline inference on Kaggle)\n",
    "student_models = []\n",
    "for ckpt_path in fold_ckpts:\n",
    "    print(f\"\\nLoading fold model: {os.path.basename(ckpt_path)}\")\n",
    "    student_models.append(load_student_model(\n",
    "        ckpt_path, backbone_weights_path=WEIGHTS_PATH))\n",
    "\n",
    "if best_ckpt:\n",
    "    print(f\"\\nLoading best model: {os.path.basename(best_ckpt)}\")\n",
    "    best_model = load_student_model(\n",
    "        best_ckpt, backbone_weights_path=WEIGHTS_PATH)\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(student_models)} student models\")\n",
    "print(\"Ready for offline inference on Kaggle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fb839a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:46.856794Z",
     "iopub.status.busy": "2025-12-15T20:02:46.856451Z",
     "iopub.status.idle": "2025-12-15T20:02:46.865036Z",
     "shell.execute_reply": "2025-12-15T20:02:46.864121Z",
     "shell.execute_reply.started": "2025-12-15T20:02:46.856771Z"
    },
    "papermill": {
     "duration": 0.016971,
     "end_time": "2025-12-11T19:12:45.760856",
     "exception": false,
     "start_time": "2025-12-11T19:12:45.743885",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create test dataset\n",
    "class BiomassTestDataset(Dataset):\n",
    "    \"\"\"Test dataset for inference - no targets needed.\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, img_dir: str, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load image\n",
    "        img_path = os.path.join(\n",
    "            self.img_dir, row['image_path'].replace('test/', ''))\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Cannot load image: {img_path}\")\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Split into left and right patches\n",
    "        h, w, c = image.shape\n",
    "        mid_w = w // 2\n",
    "\n",
    "        left_patch = image[:, :mid_w, :]\n",
    "        right_patch = image[:, mid_w:, :]\n",
    "\n",
    "        # Convert to PIL\n",
    "        left_pil = Image.fromarray(left_patch)\n",
    "        right_pil = Image.fromarray(right_patch)\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            left_tensor = self.transform(left_pil)\n",
    "            right_tensor = self.transform(right_pil)\n",
    "        else:\n",
    "            left_tensor = transforms.ToTensor()(left_pil)\n",
    "            right_tensor = transforms.ToTensor()(right_pil)\n",
    "\n",
    "        return {\n",
    "            'left_image': left_tensor,\n",
    "            'right_image': right_tensor,\n",
    "            'image_id': row['image_path'].split('/')[-1].replace('.jpg', ''),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a88be98f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:46.866330Z",
     "iopub.status.busy": "2025-12-15T20:02:46.865881Z",
     "iopub.status.idle": "2025-12-15T20:02:46.890478Z",
     "shell.execute_reply": "2025-12-15T20:02:46.889609Z",
     "shell.execute_reply.started": "2025-12-15T20:02:46.866308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loader created: 1 batches\n"
     ]
    }
   ],
   "source": [
    "# Create test dataloader\n",
    "test_dataset = BiomassTestDataset(\n",
    "    df=test_pivot,\n",
    "    img_dir=PATH_TEST_IMG,\n",
    "    transform=student_val_transform\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=min(NUM_WORKERS, 4),\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"Test loader created: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f3f8267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:46.891578Z",
     "iopub.status.busy": "2025-12-15T20:02:46.891366Z",
     "iopub.status.idle": "2025-12-15T20:02:46.911734Z",
     "shell.execute_reply": "2025-12-15T20:02:46.910838Z",
     "shell.execute_reply.started": "2025-12-15T20:02:46.891555Z"
    },
    "papermill": {
     "duration": 0.978602,
     "end_time": "2025-12-11T19:12:46.743771",
     "exception": false,
     "start_time": "2025-12-11T19:12:45.765169",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on test set...\n",
      "Using tabular_dim=0 for inference\n"
     ]
    }
   ],
   "source": [
    "# Run inference on test set with TTA\n",
    "print(\"Running inference on test set...\")\n",
    "\n",
    "all_predictions = []\n",
    "all_image_ids = []\n",
    "\n",
    "if len(student_models) == 0:\n",
    "    raise RuntimeError(\"No student models loaded for inference\")\n",
    "\n",
    "tabular_dim = student_models[0].hparams.tabular_dim\n",
    "\n",
    "print(f\"Using tabular_dim={tabular_dim} for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "900254a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:46.912838Z",
     "iopub.status.busy": "2025-12-15T20:02:46.912533Z",
     "iopub.status.idle": "2025-12-15T20:02:51.971436Z",
     "shell.execute_reply": "2025-12-15T20:02:51.970802Z",
     "shell.execute_reply.started": "2025-12-15T20:02:46.912816Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|| 1/1 [00:05<00:00,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (1, 5)\n",
      "Image IDs count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if IS_ENSEMBLE:\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(test_loader, desc=\"Inference\")):\n",
    "            # Move to device\n",
    "            batch['left_image'] = batch['left_image'].to(DEVICE)\n",
    "            batch['right_image'] = batch['right_image'].to(DEVICE)\n",
    "            batch['tabular'] = torch.zeros(\n",
    "                batch['left_image'].size(0), tabular_dim, device=DEVICE)\n",
    "\n",
    "            # Ensemble predictions from all models with TTA\n",
    "            batch_preds_list = []\n",
    "            for model in student_models:\n",
    "                model_preds = predict_model_batch(\n",
    "                    model, batch, TTA_TYPES)  # [B,5]\n",
    "                batch_preds_list.append(model_preds.cpu())\n",
    "\n",
    "            # Average predictions across models\n",
    "            batch_preds_avg = torch.stack(\n",
    "                batch_preds_list, dim=0).mean(dim=0)  # [B,5]\n",
    "\n",
    "            all_predictions.append(batch_preds_avg.numpy())\n",
    "            all_image_ids.extend(batch['image_id'])\n",
    "\n",
    "    # Concatenate all predictions\n",
    "    all_predictions_array = np.concatenate(all_predictions, axis=0)\n",
    "else:\n",
    "    model = best_model\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(test_loader, desc=\"Inference\")):\n",
    "            # Move to device\n",
    "            batch['left_image'] = batch['left_image'].to(DEVICE)\n",
    "            batch['right_image'] = batch['right_image'].to(DEVICE)\n",
    "            batch['tabular'] = torch.zeros(\n",
    "                batch['left_image'].size(0), tabular_dim, device=DEVICE)\n",
    "\n",
    "            # Single model predictions with TTA\n",
    "            model_preds = predict_model_batch(model, batch, TTA_TYPES)  # [B,5]\n",
    "\n",
    "            all_predictions.append(model_preds.cpu().numpy())\n",
    "            all_image_ids.extend(batch['image_id'])\n",
    "\n",
    "    # Concatenate all predictions\n",
    "    all_predictions_array = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "print(f\"Predictions shape: {all_predictions_array.shape}\")\n",
    "print(f\"Image IDs count: {len(all_image_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e73e7ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:51.972578Z",
     "iopub.status.busy": "2025-12-15T20:02:51.972374Z",
     "iopub.status.idle": "2025-12-15T20:02:51.981065Z",
     "shell.execute_reply": "2025-12-15T20:02:51.980418Z",
     "shell.execute_reply.started": "2025-12-15T20:02:51.972561Z"
    },
    "papermill": {
     "duration": 0.01355,
     "end_time": "2025-12-11T19:12:46.761589",
     "exception": false,
     "start_time": "2025-12-11T19:12:46.748039",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (5, 2)\n",
      "Expected shape: (5, 2)\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   0.113704\n",
      "1    ID1001187975__Dry_Dead_g  22.552826\n",
      "2   ID1001187975__Dry_Green_g  33.404621\n",
      "3   ID1001187975__Dry_Total_g  56.071148\n",
      "4         ID1001187975__GDM_g  33.518322\n"
     ]
    }
   ],
   "source": [
    "# Format submission CSV\n",
    "# Columns order: Dry_Clover_g, Dry_Dead_g, Dry_Green_g, Dry_Total_g, GDM_g\n",
    "target_names = ['Dry_Clover_g', 'Dry_Dead_g',\n",
    "                'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "\n",
    "submission_rows = []\n",
    "\n",
    "for img_idx, image_id in enumerate(all_image_ids):\n",
    "    predictions = all_predictions_array[img_idx]  # [5] values for 5 targets\n",
    "\n",
    "    for target_idx, target_name in enumerate(target_names):\n",
    "        sample_id = f\"{image_id}__{target_name}\"\n",
    "        target_value = float(predictions[target_idx])\n",
    "\n",
    "        submission_rows.append({\n",
    "            'sample_id': sample_id,\n",
    "            'target': target_value\n",
    "        })\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(f\"Expected shape: ({len(test_pivot) * 5}, 2)\")\n",
    "print(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "790b67fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:51.982025Z",
     "iopub.status.busy": "2025-12-15T20:02:51.981843Z",
     "iopub.status.idle": "2025-12-15T20:02:52.004540Z",
     "shell.execute_reply": "2025-12-15T20:02:52.003965Z",
     "shell.execute_reply.started": "2025-12-15T20:02:51.982010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SUBMISSION_NAME = 'submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4dcbdf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T20:02:52.005483Z",
     "iopub.status.busy": "2025-12-15T20:02:52.005291Z",
     "iopub.status.idle": "2025-12-15T20:02:52.027267Z",
     "shell.execute_reply": "2025-12-15T20:02:52.026454Z",
     "shell.execute_reply.started": "2025-12-15T20:02:52.005450Z"
    },
    "papermill": {
     "duration": 0.01308,
     "end_time": "2025-12-11T19:12:46.778684",
     "exception": false,
     "start_time": "2025-12-11T19:12:46.765604",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Save submission\n",
    "submission_df.to_csv(SUBMISSION_NAME, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {SUBMISSION_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94176b",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 535218,
     "modelInstanceId": 520994,
     "sourceId": 686970,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.832499,
   "end_time": "2025-12-11T19:12:49.486768",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-11T19:12:16.654269",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
