{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865c1bde",
   "metadata": {
    "papermill": {
     "duration": 0.004115,
     "end_time": "2025-12-11T19:12:20.041103",
     "exception": false,
     "start_time": "2025-12-11T19:12:20.036988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Distillation. Student Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c0636",
   "metadata": {
    "papermill": {
     "duration": 0.003092,
     "end_time": "2025-12-11T19:12:20.047506",
     "exception": false,
     "start_time": "2025-12-11T19:12:20.044414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e299f95a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:20.054508Z",
     "iopub.status.busy": "2025-12-11T19:12:20.054261Z",
     "iopub.status.idle": "2025-12-11T19:12:38.383713Z",
     "shell.execute_reply": "2025-12-11T19:12:38.382820Z"
    },
    "papermill": {
     "duration": 18.334462,
     "end_time": "2025-12-11T19:12:38.385055",
     "exception": false,
     "start_time": "2025-12-11T19:12:20.050593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.6.0+cu124\n",
      "Device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077a1548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:38.393412Z",
     "iopub.status.busy": "2025-12-11T19:12:38.392973Z",
     "iopub.status.idle": "2025-12-11T19:12:38.652255Z",
     "shell.execute_reply": "2025-12-11T19:12:38.651736Z"
    },
    "papermill": {
     "duration": 0.264771,
     "end_time": "2025-12-11T19:12:38.653430",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.388659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        # print(os.path.join(dirname, filename))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d6f31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:38.661069Z",
     "iopub.status.busy": "2025-12-11T19:12:38.660833Z",
     "iopub.status.idle": "2025-12-11T19:12:38.674456Z",
     "shell.execute_reply": "2025-12-11T19:12:38.673819Z"
    },
    "papermill": {
     "duration": 0.018698,
     "end_time": "2025-12-11T19:12:38.675573",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.656875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESCRIPTION_FULL: swinv2_tiny_window8_256-kaggle_train[5]Folds_log_fusion-mean_epochs25_bs16_gradacc1_lr0.0001_wd0.05_dr0.3_hr0.5\n",
      "Effective batch size: 16\n"
     ]
    }
   ],
   "source": [
    "cpu_count = os.cpu_count()\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "LR = 1e-4\n",
    "EPOCHS = 25\n",
    "N_FOLDS = 5\n",
    "GRAD_ACCUM = 1\n",
    "BATCH_SIZE = 16\n",
    "DROPOUT_RATE = 0.3\n",
    "# Weight for distillation loss\n",
    "# Loss = DISTILL_ALPHA * Distillation_Loss + (1 - DISTILL_ALPHA) * Hard_Loss\n",
    "DISTILL_ALPHA = 0.5\n",
    "WEIGHT_DECAY = 0.05\n",
    "HIDDEN_RATIO = 0.5\n",
    "TRAIN_SPLIT_RATIO = 0.02  # Used if N_FOLDS = 0\n",
    "\n",
    "MODEL = \"swinv2_tiny_window8_256\"\n",
    "WEIGHTS_PATH = f\"/kaggle/input/distillation-models/backbone/{MODEL}.pth\"\n",
    "MODEL_STAGE = \"student\"  # 'teacher' or 'student'\n",
    "PROJECT_NAME = \"csiro-image2biomass-prediction\"\n",
    "CHECKPOINTS_DIR = f\"./kaggle/checkpoints/{MODEL_STAGE}/\"\n",
    "# Whether to use OOF soft targets or 100% ensemble soft targets\n",
    "USE_OOF_SOFT_TARGETS = False\n",
    "\n",
    "# Each patch is 1000x1000, resize to 768x768 for vision transformers\n",
    "SIZE = 768\n",
    "USE_LOG_TARGET = True   # Whether to use log1p transformation on target variable\n",
    "FUSION_METHOD = 'mean'  # ('concat', 'mean', 'max')\n",
    "\n",
    "DESCRIPTION = \"kaggle\" + \\\n",
    "    (f\"_train{TRAIN_SPLIT_RATIO}\" if N_FOLDS == 0 else f\"_train[{N_FOLDS}]Folds\") + (\n",
    "        f\"_log\" if USE_LOG_TARGET else \"\") + f\"_fusion-{FUSION_METHOD}\"\n",
    "DESCRIPTION_FULL = MODEL + \"-\" + DESCRIPTION + \\\n",
    "    f\"_epochs{EPOCHS}_bs{BATCH_SIZE}_gradacc{GRAD_ACCUM}_lr{LR}_wd{WEIGHT_DECAY}_dr{DROPOUT_RATE}_hr{HIDDEN_RATIO}\"\n",
    "SUBMISSION_NAME = f\"{DESCRIPTION_FULL}_submission.csv\"\n",
    "SUBMISSION_NAME = f\"submission.csv\"\n",
    "SUBMISSION_ENSEMBLE_NAME = f\"{DESCRIPTION_FULL}_ensemble_submission.csv\"\n",
    "SUBMISSION_MSG = DESCRIPTION_FULL.replace(\"_\", \" \")\n",
    "\n",
    "SEED = 1488\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "pl.seed_everything(SEED)\n",
    "\n",
    "print(\"DESCRIPTION_FULL:\", DESCRIPTION_FULL)\n",
    "print(f\"Effective batch size: {BATCH_SIZE * GRAD_ACCUM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13369e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:38.683004Z",
     "iopub.status.busy": "2025-12-11T19:12:38.682783Z",
     "iopub.status.idle": "2025-12-11T19:12:38.924229Z",
     "shell.execute_reply": "2025-12-11T19:12:38.923358Z"
    },
    "papermill": {
     "duration": 0.246526,
     "end_time": "2025-12-11T19:12:38.925434",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.678908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NUM_WORKERS: 0\n",
      "\n",
      "Tesla T4\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)\n",
    "print('NUM_WORKERS:', NUM_WORKERS)\n",
    "print()\n",
    "\n",
    "# Additional Info when using cuda\n",
    "if DEVICE.type == 'cuda':\n",
    "    # clean GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # torch.set_float32_matmul_precision('high')\n",
    "\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3, 1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0baaac",
   "metadata": {
    "papermill": {
     "duration": 0.003521,
     "end_time": "2025-12-11T19:12:38.932551",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.929030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d676db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:38.940125Z",
     "iopub.status.busy": "2025-12-11T19:12:38.939895Z",
     "iopub.status.idle": "2025-12-11T19:12:38.945085Z",
     "shell.execute_reply": "2025-12-11T19:12:38.944346Z"
    },
    "papermill": {
     "duration": 0.010274,
     "end_time": "2025-12-11T19:12:38.946120",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.935846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"Dry_Clover_g\",\n",
    "    \"Dry_Dead_g\",\n",
    "    \"Dry_Green_g\",\n",
    "    \"Dry_Total_g\",\n",
    "    \"GDM_g\"\n",
    "]\n",
    "\n",
    "weights = {\n",
    "    'Dry_Green_g': 0.1,\n",
    "    'Dry_Dead_g': 0.1,\n",
    "    'Dry_Clover_g': 0.1,\n",
    "    'GDM_g': 0.2,\n",
    "    'Dry_Total_g': 0.5,\n",
    "}\n",
    "\n",
    "\n",
    "def competition_metric(y_true, y_pred) -> float:\n",
    "    \"\"\"Function to calculate the competition's official evaluation metric (weighted R2 score).\"\"\"\n",
    "    weights_array = np.array([weights[l] for l in labels])\n",
    "\n",
    "    # Align with this calculation method\n",
    "    y_weighted_mean = np.average(y_true, weights=weights_array, axis=1).mean()\n",
    "\n",
    "    # For ss_res and ss_tot, also take the weighted average on axis=1, then the mean of the result\n",
    "    ss_res = np.average((y_true - y_pred)**2,\n",
    "                        weights=weights_array, axis=1).mean()\n",
    "    ss_tot = np.average((y_true - y_weighted_mean)**2,\n",
    "                        weights=weights_array, axis=1).mean()\n",
    "\n",
    "    return 1 - ss_res / ss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da81bbf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:38.953854Z",
     "iopub.status.busy": "2025-12-11T19:12:38.953631Z",
     "iopub.status.idle": "2025-12-11T19:12:38.961408Z",
     "shell.execute_reply": "2025-12-11T19:12:38.960794Z"
    },
    "papermill": {
     "duration": 0.012976,
     "end_time": "2025-12-11T19:12:38.962524",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.949548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StudentDistillationLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom loss for Student model combining:\n",
    "    1. Distillation loss (learn from Teacher)\n",
    "    2. Hard loss (learn from real targets with competition weights)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha: float = 0.5, use_log_space: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha: Weight for distillation loss (0.5 = equal weight to Teacher and ground truth)\n",
    "            use_log_space: If True, compute loss in log space\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.use_log_space = use_log_space\n",
    "\n",
    "        # Competition weights\n",
    "        self.w_green = 0.1\n",
    "        self.w_clover = 0.1\n",
    "        self.w_dead = 0.1\n",
    "        self.w_gdm = 0.2\n",
    "        self.w_total = 0.5\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        student_preds: torch.Tensor,  # [B, 3] predictions in log space\n",
    "        hard_targets: torch.Tensor,   # [B, 3] ground truth in log space\n",
    "        soft_targets: torch.Tensor    # [B, 3] Teacher predictions in log space\n",
    "    ) -> tuple[torch.Tensor, dict]:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            total_loss: Combined loss\n",
    "            loss_dict: Dictionary with individual loss components\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. Distillation Loss (MSE with Teacher's soft targets)\n",
    "        loss_distill = F.mse_loss(student_preds, soft_targets)\n",
    "\n",
    "        # 2. Hard Loss with competition weights\n",
    "        # Individual components\n",
    "        loss_clover = F.mse_loss(\n",
    "            student_preds[:, 0], hard_targets[:, 0])  # Dry_Clover_g\n",
    "        loss_dead = F.mse_loss(\n",
    "            student_preds[:, 1], hard_targets[:, 1])  # Dry_Dead_g\n",
    "        loss_green = F.mse_loss(\n",
    "            student_preds[:, 2], hard_targets[:, 2])  # Dry_Green_g\n",
    "\n",
    "        # Derived targets (computed from components)\n",
    "        # Dry_Total_g = sum of all 3 components\n",
    "        student_total = student_preds.sum(dim=1)\n",
    "        hard_total = hard_targets.sum(dim=1)\n",
    "        loss_total = F.mse_loss(student_total, hard_total)\n",
    "\n",
    "        # GDM_g = Clover + Green\n",
    "        student_gdm = student_preds[:, 0] + \\\n",
    "            student_preds[:, 2]  # Clover + Green\n",
    "        hard_gdm = hard_targets[:, 0] + hard_targets[:, 2]\n",
    "        loss_gdm = F.mse_loss(student_gdm, hard_gdm)\n",
    "\n",
    "        # Weighted hard loss (following competition metric weights)\n",
    "        loss_hard = (\n",
    "            self.w_green * loss_green +\n",
    "            self.w_clover * loss_clover +\n",
    "            self.w_dead * loss_dead +\n",
    "            self.w_gdm * loss_gdm +\n",
    "            self.w_total * loss_total\n",
    "        )\n",
    "\n",
    "        # 3. Total loss (weighted combination)\n",
    "        total_loss = self.alpha * loss_distill + (1 - self.alpha) * loss_hard\n",
    "\n",
    "        # Return loss dict for logging\n",
    "        loss_dict = {\n",
    "            'loss_distill': loss_distill.item(),\n",
    "            'loss_hard': loss_hard.item(),\n",
    "            'loss_green': loss_green.item(),\n",
    "            'loss_clover': loss_clover.item(),\n",
    "            'loss_dead': loss_dead.item(),\n",
    "            'loss_total': loss_total.item(),\n",
    "            'loss_gdm': loss_gdm.item(),\n",
    "        }\n",
    "\n",
    "        return total_loss, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19fc000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:38.970131Z",
     "iopub.status.busy": "2025-12-11T19:12:38.969922Z",
     "iopub.status.idle": "2025-12-11T19:12:38.988219Z",
     "shell.execute_reply": "2025-12-11T19:12:38.987476Z"
    },
    "papermill": {
     "duration": 0.023609,
     "end_time": "2025-12-11T19:12:38.989333",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.965724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiomassStudentModel(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Student model for biomass prediction.\n",
    "    Uses ONLY images (dual-patch), NO tabular features.\n",
    "    Learns from Teacher's soft targets + ground truth.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_name: str = 'swinv2_tiny_window8_256',\n",
    "        num_targets: int = 3,\n",
    "        lr: float = 1e-4,\n",
    "        weight_decay: float = 1e-5,\n",
    "        hidden_ratio: float = 0.5,\n",
    "        dropout: float = 0.3,\n",
    "        fusion_method: str = 'mean',\n",
    "        distill_alpha: float = 0.5,\n",
    "        use_log_target: bool = True,\n",
    "        pretrained_backbone: bool = True  # NEW PARAMETER!\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Image backbone - load pretrained only if specified\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name,\n",
    "            pretrained=pretrained_backbone,  # CHANGED: use parameter\n",
    "            num_classes=0,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.fusion_method = fusion_method\n",
    "        self.use_log_target = use_log_target\n",
    "\n",
    "        # Get backbone output dimension\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, SIZE, SIZE)\n",
    "            feat_dim = self.backbone(dummy).shape[1]\n",
    "\n",
    "        self.feat_dim = feat_dim\n",
    "\n",
    "        # NO tabular features - only image features!\n",
    "        if self.fusion_method == 'concat':\n",
    "            self.combined_dim = feat_dim * 2\n",
    "        else:  # mean or max\n",
    "            self.combined_dim = feat_dim\n",
    "\n",
    "        # Regression heads (simpler than Teacher)\n",
    "        hidden_size = max(32, int(self.combined_dim * hidden_ratio))\n",
    "\n",
    "        def make_head():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(self.combined_dim, hidden_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_size, 1)\n",
    "            )\n",
    "\n",
    "        self.head_green = make_head()\n",
    "        self.head_clover = make_head()\n",
    "        self.head_dead = make_head()\n",
    "\n",
    "        # Custom distillation loss\n",
    "        self.criterion = StudentDistillationLoss(\n",
    "            alpha=distill_alpha,\n",
    "            use_log_space=use_log_target\n",
    "        )\n",
    "\n",
    "        # Storage for validation\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "        print(f\"Student model initialized: backbone={backbone_name}, feat_dim={feat_dim}, \"\n",
    "              f\"combined_dim={self.combined_dim}, fusion={fusion_method}, \"\n",
    "              f\"distill_alpha={distill_alpha}, pretrained_backbone={pretrained_backbone}\")\n",
    "\n",
    "    def forward(self, batch: dict) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch: dict with 'left_image', 'right_image'\n",
    "\n",
    "        Returns:\n",
    "            (green, clover, dead) predictions\n",
    "        \"\"\"\n",
    "        # Extract features from each patch\n",
    "        left_feat = self.backbone(batch['left_image'])\n",
    "        right_feat = self.backbone(batch['right_image'])\n",
    "\n",
    "        # Fuse image features\n",
    "        if self.fusion_method == 'concat':\n",
    "            img_feat = torch.cat([left_feat, right_feat], dim=1)\n",
    "        elif self.fusion_method == 'mean':\n",
    "            img_feat = (left_feat + right_feat) / 2\n",
    "        elif self.fusion_method == 'max':\n",
    "            img_feat = torch.maximum(left_feat, right_feat)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown fusion method: {self.fusion_method}\")\n",
    "\n",
    "        # Predict each target\n",
    "        green = self.head_green(img_feat).squeeze(1)\n",
    "        clover = self.head_clover(img_feat).squeeze(1)\n",
    "        dead = self.head_dead(img_feat).squeeze(1)\n",
    "\n",
    "        return green, clover, dead\n",
    "\n",
    "    def compute_all_targets(self, green: torch.Tensor, clover: torch.Tensor, dead: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute all 5 targets from 3 predicted ones\"\"\"\n",
    "        green = torch.clamp(green, min=0.0)\n",
    "        clover = torch.clamp(clover, min=0.0)\n",
    "        dead = torch.clamp(dead, min=0.0)\n",
    "\n",
    "        total = green + dead + clover\n",
    "        gdm = clover + green\n",
    "\n",
    "        all_targets = torch.stack([clover, dead, green, total, gdm], dim=1)\n",
    "        return all_targets\n",
    "\n",
    "    def training_step(self, batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        green, clover, dead = self(batch)\n",
    "\n",
    "        # Stack predictions [B, 3] in order: [clover, dead, green]\n",
    "        preds = torch.stack([clover, dead, green], dim=1)\n",
    "\n",
    "        # Compute distillation loss\n",
    "        loss, loss_dict = self.criterion(\n",
    "            preds,\n",
    "            batch['hard_targets'],\n",
    "            batch['soft_targets']\n",
    "        )\n",
    "\n",
    "        # Log all loss components\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True,\n",
    "                 batch_size=batch['hard_targets'].size(0))\n",
    "        self.log('train_loss_distill',\n",
    "                 loss_dict['loss_distill'], on_step=True, on_epoch=True)\n",
    "        self.log('train_loss_hard',\n",
    "                 loss_dict['loss_hard'], on_step=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        green_pred, clover_pred, dead_pred = self(batch)\n",
    "\n",
    "        preds = torch.stack([clover_pred, dead_pred, green_pred], dim=1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss, loss_dict = self.criterion(\n",
    "            preds,\n",
    "            batch['hard_targets'],\n",
    "            batch['soft_targets']\n",
    "        )\n",
    "\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True,\n",
    "                 batch_size=batch['hard_targets'].size(0))\n",
    "        self.log('val_loss_distill',\n",
    "                 loss_dict['loss_distill'], on_step=False, on_epoch=True)\n",
    "        self.log('val_loss_hard',\n",
    "                 loss_dict['loss_hard'], on_step=False, on_epoch=True)\n",
    "\n",
    "        # Convert to original scale for metric\n",
    "        if self.use_log_target:\n",
    "            green_pred = torch.expm1(green_pred)\n",
    "            clover_pred = torch.expm1(clover_pred)\n",
    "            dead_pred = torch.expm1(dead_pred)\n",
    "\n",
    "            hard_targets_original = torch.expm1(batch['hard_targets'])\n",
    "        else:\n",
    "            hard_targets_original = batch['hard_targets']\n",
    "\n",
    "        # Compute all 5 targets\n",
    "        preds_all = self.compute_all_targets(\n",
    "            green_pred, clover_pred, dead_pred)\n",
    "\n",
    "        clover_true = hard_targets_original[:, 0]\n",
    "        dead_true = hard_targets_original[:, 1]\n",
    "        green_true = hard_targets_original[:, 2]\n",
    "        targets_all = self.compute_all_targets(\n",
    "            green_true, clover_true, dead_true)\n",
    "\n",
    "        self.validation_step_outputs.append({\n",
    "            'preds': preds_all.detach().cpu(),\n",
    "            'targets': targets_all.detach().cpu()\n",
    "        })\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        if len(self.validation_step_outputs) == 0:\n",
    "            return\n",
    "\n",
    "        all_preds = torch.cat(\n",
    "            [x['preds'] for x in self.validation_step_outputs], dim=0).numpy()\n",
    "        all_targets = torch.cat(\n",
    "            [x['targets'] for x in self.validation_step_outputs], dim=0).numpy()\n",
    "\n",
    "        comp_metric = competition_metric(all_targets, all_preds)\n",
    "        self.log('val_comp_metric', comp_metric, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def predict_step(self, batch: dict, batch_idx: int) -> torch.Tensor:\n",
    "        green, clover, dead = self(batch)\n",
    "        preds = torch.stack([clover, dead, green], dim=1)\n",
    "\n",
    "        if self.use_log_target:\n",
    "            preds = torch.expm1(preds)\n",
    "\n",
    "        preds = torch.clamp(preds, min=0.0)\n",
    "        return preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "\n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=self.trainer.max_epochs or 20,\n",
    "            eta_min=self.lr * 0.01\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'epoch'\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc59dd50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:38.996769Z",
     "iopub.status.busy": "2025-12-11T19:12:38.996566Z",
     "iopub.status.idle": "2025-12-11T19:12:40.693006Z",
     "shell.execute_reply": "2025-12-11T19:12:40.692116Z"
    },
    "papermill": {
     "duration": 1.701985,
     "end_time": "2025-12-11T19:12:40.694624",
     "exception": false,
     "start_time": "2025-12-11T19:12:38.992639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://github.com/SwinTransformer/storage/releases/download/v2.0.0/swinv2_tiny_patch4_window8_256.pth', 'hf_hub_id': 'timm/swinv2_tiny_window8_256.ms_in1k', 'architecture': 'swinv2_tiny_window8_256', 'tag': 'ms_in1k', 'custom_load': False, 'input_size': (3, 256, 256), 'fixed_input_size': True, 'interpolation': 'bicubic', 'crop_pct': 0.9, 'crop_mode': 'center', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'num_classes': 1000, 'pool_size': (8, 8), 'first_conv': 'patch_embed.proj', 'classifier': 'head.fc', 'license': 'mit'}\n"
     ]
    }
   ],
   "source": [
    "# Image backbone (processes each patch independently)\n",
    "temp_backbone = timm.create_model(MODEL, pretrained=False)\n",
    "\n",
    "checkpoint = torch.load(WEIGHTS_PATH, map_location='cpu')  # FIXME: 'cuda' \n",
    "temp_backbone.load_state_dict(checkpoint)\n",
    "\n",
    "temp_backbone.reset_classifier(0, global_pool='avg')\n",
    "\n",
    "print(temp_backbone.default_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1586a378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:40.704683Z",
     "iopub.status.busy": "2025-12-11T19:12:40.704457Z",
     "iopub.status.idle": "2025-12-11T19:12:40.978567Z",
     "shell.execute_reply": "2025-12-11T19:12:40.977920Z"
    },
    "papermill": {
     "duration": 0.280794,
     "end_time": "2025-12-11T19:12:40.979953",
     "exception": false,
     "start_time": "2025-12-11T19:12:40.699159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone expected input size: (3, 256, 256), using SIZE=256\n",
      "Backbone expected mean: (0.485, 0.456, 0.406), std: (0.229, 0.224, 0.225)\n"
     ]
    }
   ],
   "source": [
    "inputs_size = temp_backbone.default_cfg['input_size']\n",
    "mean = temp_backbone.default_cfg['mean']\n",
    "std = temp_backbone.default_cfg['std']\n",
    "\n",
    "SIZE = int(inputs_size[1]) if inputs_size is not None and inputs_size[1] == inputs_size[2] else 256\n",
    "print(f\"Backbone expected input size: {inputs_size}, using SIZE={SIZE}\")\n",
    "print(f\"Backbone expected mean: {mean}, std: {std}\")\n",
    "\n",
    "# Get backbone output dimension\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        dummy = torch.randn(1, 3, SIZE, SIZE)\n",
    "        feat_dim = temp_backbone(dummy).shape[1]\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting backbone feature dimension: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad7904b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:40.988400Z",
     "iopub.status.busy": "2025-12-11T19:12:40.988135Z",
     "iopub.status.idle": "2025-12-11T19:12:40.992065Z",
     "shell.execute_reply": "2025-12-11T19:12:40.991493Z"
    },
    "papermill": {
     "duration": 0.009317,
     "end_time": "2025-12-11T19:12:40.993095",
     "exception": false,
     "start_time": "2025-12-11T19:12:40.983778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "student_val_transform = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b494fd8",
   "metadata": {
    "papermill": {
     "duration": 0.003342,
     "end_time": "2025-12-11T19:12:40.999896",
     "exception": false,
     "start_time": "2025-12-11T19:12:40.996554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Student Model Inference on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c97fc78c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:41.007903Z",
     "iopub.status.busy": "2025-12-11T19:12:41.007699Z",
     "iopub.status.idle": "2025-12-11T19:12:41.010988Z",
     "shell.execute_reply": "2025-12-11T19:12:41.010419Z"
    },
    "papermill": {
     "duration": 0.008328,
     "end_time": "2025-12-11T19:12:41.012015",
     "exception": false,
     "start_time": "2025-12-11T19:12:41.003687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_DATA = '/kaggle/input/csiro-biomass'\n",
    "STUDENT_MODELS_DIR = '/kaggle/input/distillation-models/student'\n",
    "PATH_TEST_CSV = os.path.join(PATH_DATA, 'test.csv')\n",
    "PATH_TEST_IMG = os.path.join(PATH_DATA, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d08303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:41.019779Z",
     "iopub.status.busy": "2025-12-11T19:12:41.019584Z",
     "iopub.status.idle": "2025-12-11T19:12:41.056030Z",
     "shell.execute_reply": "2025-12-11T19:12:41.055336Z"
    },
    "papermill": {
     "duration": 0.041627,
     "end_time": "2025-12-11T19:12:41.057105",
     "exception": false,
     "start_time": "2025-12-11T19:12:41.015478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 1\n",
      "              image_path                   sample_id   target_name\n",
      "0  test/ID1001187975.jpg  ID1001187975__Dry_Clover_g  Dry_Clover_g\n"
     ]
    }
   ],
   "source": [
    "# Load test CSV\n",
    "test_df = pd.read_csv(PATH_TEST_CSV)\n",
    "test_df = test_df[~test_df['target_name'].isin(['Dry_Total_g', 'GDM_g'])]\n",
    "\n",
    "# Pivot to one row per image\n",
    "test_pivot = test_df.pivot_table(\n",
    "    index='image_path',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "print(f\"Test set size: {len(test_pivot)}\")\n",
    "print(test_pivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a254b7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:41.065121Z",
     "iopub.status.busy": "2025-12-11T19:12:41.064924Z",
     "iopub.status.idle": "2025-12-11T19:12:45.737686Z",
     "shell.execute_reply": "2025-12-11T19:12:45.736663Z"
    },
    "papermill": {
     "duration": 4.678651,
     "end_time": "2025-12-11T19:12:45.739256",
     "exception": false,
     "start_time": "2025-12-11T19:12:41.060605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 student checkpoints:\n",
      "  - student_best_fold1.ckpt\n",
      "  - student_best_fold4.ckpt\n",
      "\n",
      "Loading: student_best_fold1.ckpt\n",
      "Student model initialized: backbone=swinv2_tiny_window8_256, feat_dim=768, combined_dim=768, fusion=mean, distill_alpha=0.5, pretrained_backbone=False\n",
      "Loaded (backbone: swinv2_tiny_window8_256, no internet required)\n",
      "\n",
      "Loading: student_best_fold4.ckpt\n",
      "Student model initialized: backbone=swinv2_tiny_window8_256, feat_dim=768, combined_dim=768, fusion=mean, distill_alpha=0.5, pretrained_backbone=False\n",
      "Loaded (backbone: swinv2_tiny_window8_256, no internet required)\n",
      "\n",
      "Successfully loaded 2 student models\n",
      "Ready for offline inference on Kaggle!\n"
     ]
    }
   ],
   "source": [
    "# Find all ckpt files\n",
    "ckpt_files = sorted([f for f in os.listdir(\n",
    "    STUDENT_MODELS_DIR) if f.endswith('.ckpt')])\n",
    "print(f\"Found {len(ckpt_files)} student checkpoints:\")\n",
    "for f in ckpt_files:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Load models WITHOUT internet (offline inference on Kaggle)\n",
    "student_models = []\n",
    "for ckpt_file in ckpt_files:\n",
    "    ckpt_path = os.path.join(STUDENT_MODELS_DIR, ckpt_file)\n",
    "    print(f\"\\nLoading: {ckpt_file}\")\n",
    "\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "    hparams = checkpoint['hyper_parameters']\n",
    "    \n",
    "    # Create model WITHOUT pretrained backbone (all weights in checkpoint)\n",
    "    model = BiomassStudentModel(\n",
    "        backbone_name=hparams['backbone_name'],\n",
    "        num_targets=hparams['num_targets'],\n",
    "        lr=hparams['lr'],\n",
    "        weight_decay=hparams['weight_decay'],\n",
    "        hidden_ratio=hparams['hidden_ratio'],\n",
    "        dropout=hparams['dropout'],\n",
    "        fusion_method=hparams['fusion_method'],\n",
    "        distill_alpha=hparams['distill_alpha'],\n",
    "        use_log_target=hparams['use_log_target'],\n",
    "        pretrained_backbone=False  # IMPORTANT: No internet needed!\n",
    "    )\n",
    "    \n",
    "    # Load all trained weights from checkpoint\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    student_models.append(model)\n",
    "    \n",
    "    print(f\"Loaded (backbone: {hparams['backbone_name']}, no internet required)\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(student_models)} student models\")\n",
    "print(\"Ready for offline inference on Kaggle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb839a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:45.749267Z",
     "iopub.status.busy": "2025-12-11T19:12:45.749041Z",
     "iopub.status.idle": "2025-12-11T19:12:45.759525Z",
     "shell.execute_reply": "2025-12-11T19:12:45.758695Z"
    },
    "papermill": {
     "duration": 0.016971,
     "end_time": "2025-12-11T19:12:45.760856",
     "exception": false,
     "start_time": "2025-12-11T19:12:45.743885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loader created: 1 batches\n"
     ]
    }
   ],
   "source": [
    "# Create test dataset\n",
    "class BiomassTestDataset(Dataset):\n",
    "    \"\"\"Test dataset for inference - no targets needed.\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, img_dir: str, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load image\n",
    "        img_path = os.path.join(\n",
    "            self.img_dir, row['image_path'].replace('test/', ''))\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Cannot load image: {img_path}\")\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Split into left and right patches\n",
    "        h, w, c = image.shape\n",
    "        mid_w = w // 2\n",
    "\n",
    "        left_patch = image[:, :mid_w, :]\n",
    "        right_patch = image[:, mid_w:, :]\n",
    "\n",
    "        # Convert to PIL\n",
    "        left_pil = Image.fromarray(left_patch)\n",
    "        right_pil = Image.fromarray(right_patch)\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            left_tensor = self.transform(left_pil)\n",
    "            right_tensor = self.transform(right_pil)\n",
    "        else:\n",
    "            left_tensor = transforms.ToTensor()(left_pil)\n",
    "            right_tensor = transforms.ToTensor()(right_pil)\n",
    "\n",
    "        return {\n",
    "            'left_image': left_tensor,\n",
    "            'right_image': right_tensor,\n",
    "            'image_id': row['image_path'].split('/')[-1].replace('.jpg', '')\n",
    "        }\n",
    "\n",
    "\n",
    "# Create test dataloader\n",
    "test_dataset = BiomassTestDataset(\n",
    "    df=test_pivot,\n",
    "    img_dir=PATH_TEST_IMG,\n",
    "    transform=student_val_transform\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=min(NUM_WORKERS, 4),\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"Test loader created: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f3f8267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:45.770355Z",
     "iopub.status.busy": "2025-12-11T19:12:45.770150Z",
     "iopub.status.idle": "2025-12-11T19:12:46.742565Z",
     "shell.execute_reply": "2025-12-11T19:12:46.741710Z"
    },
    "papermill": {
     "duration": 0.978602,
     "end_time": "2025-12-11T19:12:46.743771",
     "exception": false,
     "start_time": "2025-12-11T19:12:45.765169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (1, 5)\n",
      "Image IDs count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference on test set\n",
    "print(\"Running inference on test set...\")\n",
    "\n",
    "all_predictions = []\n",
    "all_image_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(test_loader, desc=\"Inference\")):\n",
    "        # Move to device\n",
    "        batch['left_image'] = batch['left_image'].to(DEVICE)\n",
    "        batch['right_image'] = batch['right_image'].to(DEVICE)\n",
    "\n",
    "        # Ensemble predictions from all models\n",
    "        batch_preds_list = []\n",
    "\n",
    "        for model in student_models:\n",
    "            green_pred, clover_pred, dead_pred = model(batch)\n",
    "\n",
    "            # Convert to original scale if needed\n",
    "            if USE_LOG_TARGET:\n",
    "                green_pred = torch.expm1(green_pred)\n",
    "                clover_pred = torch.expm1(clover_pred)\n",
    "                dead_pred = torch.expm1(dead_pred)\n",
    "\n",
    "            # Clamp to non-negative\n",
    "            green_pred = torch.clamp(green_pred, min=0.0)\n",
    "            clover_pred = torch.clamp(clover_pred, min=0.0)\n",
    "            dead_pred = torch.clamp(dead_pred, min=0.0)\n",
    "\n",
    "            # Compute all 5 targets\n",
    "            total = green_pred + clover_pred + dead_pred\n",
    "            gdm = clover_pred + green_pred\n",
    "\n",
    "            # Stack: [clover, dead, green, total, gdm]\n",
    "            preds_all = torch.stack(\n",
    "                [clover_pred, dead_pred, green_pred, total, gdm], dim=1)\n",
    "            batch_preds_list.append(preds_all.cpu().numpy())\n",
    "\n",
    "        # Average predictions across models\n",
    "        batch_preds_avg = np.mean(batch_preds_list, axis=0)  # [B, 5]\n",
    "\n",
    "        all_predictions.append(batch_preds_avg)\n",
    "        all_image_ids.extend(batch['image_id'])\n",
    "\n",
    "# Concatenate all predictions\n",
    "all_predictions_array = np.concatenate(all_predictions, axis=0)\n",
    "print(f\"Predictions shape: {all_predictions_array.shape}\")\n",
    "print(f\"Image IDs count: {len(all_image_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e73e7ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:46.753154Z",
     "iopub.status.busy": "2025-12-11T19:12:46.752693Z",
     "iopub.status.idle": "2025-12-11T19:12:46.760545Z",
     "shell.execute_reply": "2025-12-11T19:12:46.759842Z"
    },
    "papermill": {
     "duration": 0.01355,
     "end_time": "2025-12-11T19:12:46.761589",
     "exception": false,
     "start_time": "2025-12-11T19:12:46.748039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (5, 2)\n",
      "Expected shape: (5, 2)\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   0.055007\n",
      "1    ID1001187975__Dry_Dead_g  30.748314\n",
      "2   ID1001187975__Dry_Green_g  21.311224\n",
      "3   ID1001187975__Dry_Total_g  52.114544\n",
      "4         ID1001187975__GDM_g  21.366230\n"
     ]
    }
   ],
   "source": [
    "# Format submission CSV\n",
    "# Columns order: Dry_Clover_g, Dry_Dead_g, Dry_Green_g, Dry_Total_g, GDM_g\n",
    "target_names = ['Dry_Clover_g', 'Dry_Dead_g',\n",
    "                'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "\n",
    "submission_rows = []\n",
    "\n",
    "for img_idx, image_id in enumerate(all_image_ids):\n",
    "    predictions = all_predictions_array[img_idx]  # [5] values for 5 targets\n",
    "\n",
    "    for target_idx, target_name in enumerate(target_names):\n",
    "        sample_id = f\"{image_id}__{target_name}\"\n",
    "        target_value = float(predictions[target_idx])\n",
    "\n",
    "        submission_rows.append({\n",
    "            'sample_id': sample_id,\n",
    "            'target': target_value\n",
    "        })\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(f\"Expected shape: ({len(test_pivot) * 5}, 2)\")\n",
    "print(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4dcbdf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T19:12:46.770420Z",
     "iopub.status.busy": "2025-12-11T19:12:46.770195Z",
     "iopub.status.idle": "2025-12-11T19:12:46.777650Z",
     "shell.execute_reply": "2025-12-11T19:12:46.777008Z"
    },
    "papermill": {
     "duration": 0.01308,
     "end_time": "2025-12-11T19:12:46.778684",
     "exception": false,
     "start_time": "2025-12-11T19:12:46.765604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Save submission\n",
    "submission_df.to_csv(SUBMISSION_NAME, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {SUBMISSION_NAME}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 14898463,
     "datasetId": 8990306,
     "sourceId": 14114255,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.832499,
   "end_time": "2025-12-11T19:12:49.486768",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-11T19:12:16.654269",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
